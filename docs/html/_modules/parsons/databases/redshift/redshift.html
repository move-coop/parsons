

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>parsons.databases.redshift.redshift &mdash; Parsons 0.5 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../../index.html" class="icon icon-home"> Parsons
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Integrations</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../action_kit.html">ActionKit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../action_network.html">Action Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../airtable.html">Airtable</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../aws.html">Amazon Web Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../azure.html">Azure: Blob Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bill_com.html">Bill.com</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bloomerang.html">Bloomerang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../box.html">Box</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../braintree.html">Braintree</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../civis.html">Civis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../copper.html">Copper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../crowdtangle.html">CrowdTangle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../facebook_ads.html">FacebookAds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../freshdesk.html">Freshdesk</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../github.html">GitHub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../google.html">Google</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hustle.html">Hustle</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mailchimp.html">Mailchimp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mobilize_america.html">Mobilize America</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../newmode.html">New/Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ngpvan.html">NGPVAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pdi.html">PDI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../p2a.html">Phone2Action</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../redash.html">Redash</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rockthevote.html">Rock the Vote</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../salesforce.html">Salesforce</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sftp.html">SFTP</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../targetsmart.html">TargetSmart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../turbovote.html">TurboVote</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../twilio.html">Twilio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../zoom.html">Zoom</a></li>
</ul>
<p class="caption"><span class="caption-text">Enhancements</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../census_geocoder.html">US Census Geocoder</a></li>
</ul>
<p class="caption"><span class="caption-text">Framework</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../dbsync.html">Database Sync</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../table.html">Parsons Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notifications.html">Notifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utilities.html">Utilities</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributor Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../contributing.html">Contributing to Parsons</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../build_a_connector.html">How to Build a Connector</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">Parsons</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
        
      <li>parsons.databases.redshift.redshift</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for parsons.databases.redshift.redshift</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">parsons.etl.table</span> <span class="kn">import</span> <span class="n">Table</span>
<span class="kn">from</span> <span class="nn">parsons.databases.redshift.rs_copy_table</span> <span class="kn">import</span> <span class="n">RedshiftCopyTable</span>
<span class="kn">from</span> <span class="nn">parsons.databases.redshift.rs_create_table</span> <span class="kn">import</span> <span class="n">RedshiftCreateTable</span>
<span class="kn">from</span> <span class="nn">parsons.databases.redshift.rs_table_utilities</span> <span class="kn">import</span> <span class="n">RedshiftTableUtilities</span>
<span class="kn">from</span> <span class="nn">parsons.databases.redshift.rs_schema</span> <span class="kn">import</span> <span class="n">RedshiftSchema</span>
<span class="kn">from</span> <span class="nn">parsons.databases.table</span> <span class="kn">import</span> <span class="n">BaseTable</span>
<span class="kn">from</span> <span class="nn">parsons.utilities</span> <span class="kn">import</span> <span class="n">files</span>
<span class="kn">import</span> <span class="nn">psycopg2</span>
<span class="kn">import</span> <span class="nn">psycopg2.extras</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">petl</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">contextmanager</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Max number of rows that we query at a time, so we can avoid loading huge</span>
<span class="c1"># data sets into memory.</span>
<span class="c1"># 100k rows per batch at ~1k bytes each = ~100MB per batch.</span>
<span class="n">QUERY_BATCH_SIZE</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="Redshift"><a class="viewcode-back" href="../../../../aws.html#parsons.Redshift">[docs]</a><span class="k">class</span> <span class="nc">Redshift</span><span class="p">(</span><span class="n">RedshiftCreateTable</span><span class="p">,</span> <span class="n">RedshiftCopyTable</span><span class="p">,</span> <span class="n">RedshiftTableUtilities</span><span class="p">,</span> <span class="n">RedshiftSchema</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Redshift class to connect to database.</span>

<span class="sd">    Args:</span>
<span class="sd">        username: str</span>
<span class="sd">            Required if env variable ``REDSHIFT_USERNAME`` not populated</span>
<span class="sd">        password: str</span>
<span class="sd">            Required if env variable ``REDSHIFT_PASSWORD`` not populated</span>
<span class="sd">        host: str</span>
<span class="sd">            Required if env variable ``REDSHIFT_HOST`` not populated</span>
<span class="sd">        db: str</span>
<span class="sd">            Required if env variable ``REDSHIFT_DB`` not populated</span>
<span class="sd">        port: int</span>
<span class="sd">            Required if env variable ``REDSHIFT_PORT`` not populated. Port 5439 is typical.</span>
<span class="sd">        timeout: int</span>
<span class="sd">            Seconds to timeout if connection not established</span>
<span class="sd">        s3_temp_bucket: str</span>
<span class="sd">            Name of the S3 bucket that will be used for storing data during bulk transfers.</span>
<span class="sd">            Required if you intend to perform bulk data transfers (eg. the copy_s3 method),</span>
<span class="sd">            and env variable ``S3_TEMP_BUCKET`` is not populated.</span>
<span class="sd">        aws_access_key_id: str</span>
<span class="sd">            The default AWS access key id for copying data from S3 into Redshift</span>
<span class="sd">            when running copy/upsert/etc methods.</span>
<span class="sd">            This will default to environment variable AWS_ACCESS_KEY_ID.</span>
<span class="sd">        aws_secret_access_key: str</span>
<span class="sd">            The default AWS secret access key for copying data from S3 into Redshift</span>
<span class="sd">            when running copy/upsert/etc methods.</span>
<span class="sd">            This will default to environment variable AWS_SECRET_ACCESS_KEY.</span>
<span class="sd">        iam_role: str</span>
<span class="sd">            AWS IAM Role ARN string -- an optional, different way for credentials to</span>
<span class="sd">            be provided in the Redshift copy command that does not require an access key.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">username</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">host</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">db</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">s3_temp_bucket</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iam_role</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">username</span> <span class="o">=</span> <span class="n">username</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;REDSHIFT_USERNAME&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">password</span> <span class="o">=</span> <span class="n">password</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;REDSHIFT_PASSWORD&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">host</span> <span class="o">=</span> <span class="n">host</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;REDSHIFT_HOST&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">db</span> <span class="o">=</span> <span class="n">db</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;REDSHIFT_DB&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">port</span> <span class="o">=</span> <span class="n">port</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;REDSHIFT_PORT&#39;</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;Connection info missing. Most include as kwarg or &quot;</span>
                         <span class="s2">&quot;env variable.&quot;</span><span class="p">)</span>
            <span class="k">raise</span> <span class="n">error</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">timeout</span> <span class="o">=</span> <span class="n">timeout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dialect</span> <span class="o">=</span> <span class="s1">&#39;redshift&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s3_temp_bucket</span> <span class="o">=</span> <span class="n">s3_temp_bucket</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;S3_TEMP_BUCKET&#39;</span><span class="p">)</span>
        <span class="c1"># We don&#39;t check/load the environment variables for aws_* here</span>
        <span class="c1"># because the logic in S3() and rs_copy_table.py does already.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aws_access_key_id</span> <span class="o">=</span> <span class="n">aws_access_key_id</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aws_secret_access_key</span> <span class="o">=</span> <span class="n">aws_secret_access_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iam_role</span> <span class="o">=</span> <span class="n">iam_role</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">connection</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate a Redshift connection.</span>
<span class="sd">        The connection is set up as a python &quot;context manager&quot;, so it will be closed</span>
<span class="sd">        automatically (and all queries committed) when the connection goes out of scope.</span>

<span class="sd">        When using the connection, make sure to put it in a ``with`` block (necessary for</span>
<span class="sd">        any context manager):</span>
<span class="sd">        ``with rs.connection() as conn:``</span>

<span class="sd">        `Returns:`</span>
<span class="sd">            Psycopg2 `connection` object</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Create a psycopg2 connection and cursor</span>
        <span class="n">conn</span> <span class="o">=</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">user</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">password</span><span class="p">,</span>
                                <span class="n">host</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">host</span><span class="p">,</span> <span class="n">dbname</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">db</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">port</span><span class="p">,</span>
                                <span class="n">connect_timeout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">timeout</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">conn</span>

            <span class="n">conn</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">conn</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">cursor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">connection</span><span class="p">):</span>
        <span class="n">cur</span> <span class="o">=</span> <span class="n">connection</span><span class="o">.</span><span class="n">cursor</span><span class="p">(</span><span class="n">cursor_factory</span><span class="o">=</span><span class="n">psycopg2</span><span class="o">.</span><span class="n">extras</span><span class="o">.</span><span class="n">DictCursor</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">cur</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">cur</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">query</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sql</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Execute a query against the Redshift database. Will return ``None``</span>
<span class="sd">        if the query returns zero rows.</span>

<span class="sd">        To include python variables in your query, it is recommended to pass them as parameters,</span>
<span class="sd">        following the `psycopg style &lt;http://initd.org/psycopg/docs/usage.html#passing-parameters-to-sql-queries&gt;`_.</span>
<span class="sd">        Using the ``parameters`` argument ensures that values are escaped properly, and avoids SQL</span>
<span class="sd">        injection attacks.</span>

<span class="sd">        **Parameter Examples**</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Note that the name contains a quote, which could break your query if not escaped</span>
<span class="sd">            # properly.</span>
<span class="sd">            name = &quot;Beatrice O&#39;Brady&quot;</span>
<span class="sd">            sql = &quot;SELECT * FROM my_table WHERE name = %s&quot;</span>
<span class="sd">            rs.query(sql, parameters=[name])</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            names = [&quot;Allen Smith&quot;, &quot;Beatrice O&#39;Brady&quot;, &quot;Cathy Thompson&quot;]</span>
<span class="sd">            placeholders = &#39;, &#39;.join(&#39;%s&#39; for item in names)</span>
<span class="sd">            sql = f&quot;SELECT * FROM my_table WHERE name IN ({placeholders})&quot;</span>
<span class="sd">            rs.query(sql, parameters=names)</span>

<span class="sd">        `Args:`</span>
<span class="sd">            sql: str</span>
<span class="sd">                A valid SQL statement</span>
<span class="sd">            parameters: list</span>
<span class="sd">                A list of python variables to be converted into SQL values in your query</span>

<span class="sd">        `Returns:`</span>
<span class="sd">            Parsons Table</span>
<span class="sd">                See :ref:`parsons-table` for output options.</span>

<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: E501</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">query_with_connection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Execute a query against the Redshift database, with an existing connection.</span>
<span class="sd">        Useful for batching queries together. Will return ``None`` if the query</span>
<span class="sd">        returns zero rows.</span>

<span class="sd">        `Args:`</span>
<span class="sd">            sql: str</span>
<span class="sd">                A valid SQL statement</span>
<span class="sd">            connection: obj</span>
<span class="sd">                A connection object obtained from ``redshift.connection()``</span>
<span class="sd">            parameters: list</span>
<span class="sd">                A list of python variables to be converted into SQL values in your query</span>
<span class="sd">            commit: boolean</span>
<span class="sd">                Whether to commit the transaction immediately. If ``False`` the transaction will</span>
<span class="sd">                be committed when the connection goes out of scope and is closed (or you can</span>
<span class="sd">                commit manually with ``connection.commit()``).</span>

<span class="sd">        `Returns:`</span>
<span class="sd">            Parsons Table</span>
<span class="sd">                See :ref:`parsons-table` for output options.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># To Do: Have it return an ordered dict to return the</span>
        <span class="c1">#        rows in the correct order</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">cursor</span><span class="p">(</span><span class="n">connection</span><span class="p">)</span> <span class="k">as</span> <span class="n">cursor</span><span class="p">:</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SQL Query: </span><span class="si">{</span><span class="n">sql</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">cursor</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">commit</span><span class="p">:</span>
                <span class="n">connection</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>

            <span class="c1"># If the cursor is empty, don&#39;t cause an error</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s1">&#39;Query returned 0 rows&#39;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>

            <span class="k">else</span><span class="p">:</span>

                <span class="c1"># Fetch the data in batches, and &quot;pickle&quot; the rows to a temp file.</span>
                <span class="c1"># (We pickle rather than writing to, say, a CSV, so that we maintain</span>
                <span class="c1"># all the type information for each field.)</span>

                <span class="n">temp_file</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">create_temp_file</span><span class="p">()</span>

                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">temp_file</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="c1"># Grab the header</span>
                    <span class="n">header</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">cursor</span><span class="o">.</span><span class="n">description</span><span class="p">]</span>
                    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">header</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

                    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                        <span class="n">batch</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">fetchmany</span><span class="p">(</span><span class="n">QUERY_BATCH_SIZE</span><span class="p">)</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="n">batch</span><span class="p">:</span>
                            <span class="k">break</span>

                        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Fetched </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="si">}</span><span class="s1"> rows.&#39;</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
                            <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">f</span><span class="p">)</span>

                <span class="c1"># Load a Table from the file</span>
                <span class="n">final_tbl</span> <span class="o">=</span> <span class="n">Table</span><span class="p">(</span><span class="n">petl</span><span class="o">.</span><span class="n">frompickle</span><span class="p">(</span><span class="n">temp_file</span><span class="p">))</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Query returned </span><span class="si">{</span><span class="n">final_tbl</span><span class="o">.</span><span class="n">num_rows</span><span class="si">}</span><span class="s1"> rows.&#39;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">final_tbl</span>

    <span class="k">def</span> <span class="nf">copy_s3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">manifest</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">data_type</span><span class="o">=</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span>
                <span class="n">csv_delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="s1">&#39;fail&#39;</span><span class="p">,</span> <span class="n">max_errors</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">distkey</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sortkey</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">varchar_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">statupdate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compupdate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ignoreheader</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">acceptanydate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">dateformat</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">timeformat</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">emptyasnull</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">blanksasnull</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nullas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">acceptinvchars</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncatecolumns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">columntypes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specifycols</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bucket_region</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copy a file from s3 to Redshift.</span>

<span class="sd">        `Args:`</span>
<span class="sd">            table_name: str</span>
<span class="sd">                The table name and schema (``tmc.cool_table``) to point the file.</span>
<span class="sd">            bucket: str</span>
<span class="sd">                The s3 bucket where the file or manifest is located.</span>
<span class="sd">            key: str</span>
<span class="sd">                The key of the file or manifest in the s3 bucket.</span>
<span class="sd">            manifest: str</span>
<span class="sd">                If using a manifest</span>
<span class="sd">            data_type: str</span>
<span class="sd">                The data type of the file. Only ``csv`` supported currently.</span>
<span class="sd">            csv_delimiter: str</span>
<span class="sd">                The delimiter of the ``csv``. Only relevant if data_type is ``csv``.</span>
<span class="sd">            compression: str</span>
<span class="sd">                If specified (``gzip``), will attempt to decompress the file.</span>
<span class="sd">            if_exists: str</span>
<span class="sd">                If the table already exists, either ``fail``, ``append``, ``drop``</span>
<span class="sd">                or ``truncate`` the table.</span>
<span class="sd">            max_errors: int</span>
<span class="sd">                The maximum number of rows that can error and be skipped before</span>
<span class="sd">                the job fails.</span>
<span class="sd">            distkey: str</span>
<span class="sd">                The column name of the distkey</span>
<span class="sd">            sortkey: str</span>
<span class="sd">                The column name of the sortkey</span>
<span class="sd">            padding: float</span>
<span class="sd">                A percentage padding to add to varchar columns if creating a new table. This is</span>
<span class="sd">                helpful to add a buffer for future copies in which the data might be wider.</span>
<span class="sd">            varchar_max: list</span>
<span class="sd">                A list of columns in which to set the width of the varchar column to 65,535</span>
<span class="sd">                characters.</span>
<span class="sd">            statupate: boolean</span>
<span class="sd">                Governs automatic computation and refresh of optimizer statistics at the end</span>
<span class="sd">                of a successful COPY command.</span>
<span class="sd">            compupdate: boolean</span>
<span class="sd">                Controls whether compression encodings are automatically applied during a COPY.</span>
<span class="sd">            ignore_header: int</span>
<span class="sd">                The number of header rows to skip. Ignored if data_type is ``json``.</span>
<span class="sd">            acceptanydate: boolean</span>
<span class="sd">                Allows any date format, including invalid formats such as 00/00/00 00:00:00, to be</span>
<span class="sd">                loaded without generating an error.</span>
<span class="sd">            emptyasnull: boolean</span>
<span class="sd">                Indicates that Amazon Redshift should load empty char and varchar fields</span>
<span class="sd">                as ``NULL``.</span>
<span class="sd">            blanksasnull: boolean</span>
<span class="sd">                Loads blank varchar fields, which consist of only white space characters,</span>
<span class="sd">                as ``NULL``.</span>
<span class="sd">            nullas: str</span>
<span class="sd">                Loads fields that match string as NULL</span>
<span class="sd">            acceptinvchars: boolean</span>
<span class="sd">                Enables loading of data into VARCHAR columns even if the data contains</span>
<span class="sd">                invalid UTF-8 characters.</span>
<span class="sd">            dateformat: str</span>
<span class="sd">                Set the date format. Defaults to ``auto``.</span>
<span class="sd">            timeformat: str</span>
<span class="sd">                Set the time format. Defaults to ``auto``.</span>
<span class="sd">            truncatecolumns: boolean</span>
<span class="sd">                If the table already exists, truncates data in columns to the appropriate number</span>
<span class="sd">                of characters so that it fits the column specification. Applies only to columns</span>
<span class="sd">                with a VARCHAR or CHAR data type, and rows 4 MB or less in size.</span>
<span class="sd">            columntypes: dict</span>
<span class="sd">                Optional map of column name to redshift column type, overriding the usual type</span>
<span class="sd">                inference. You only specify the columns you want to override, eg.</span>
<span class="sd">                ``columntypes={&#39;phone&#39;: &#39;varchar(12)&#39;, &#39;age&#39;: &#39;int&#39;})``.</span>
<span class="sd">            specifycols: boolean</span>
<span class="sd">                Adds a column list to the Redshift `COPY` command, allowing for the source table</span>
<span class="sd">                in an append to have the columnns out of order, and to have fewer columns with any</span>
<span class="sd">                leftover target table columns filled in with the `DEFAULT` value.</span>

<span class="sd">                This will fail if all of the source table&#39;s columns do not match a column in the</span>
<span class="sd">                target table. This will also fail if the target table has an `IDENTITY`</span>
<span class="sd">                column and that column name is among the source table&#39;s columns.</span>
<span class="sd">            aws_access_key_id:</span>
<span class="sd">                An AWS access key granted to the bucket where the file is located. Not required</span>
<span class="sd">                if keys are stored as environmental variables.</span>
<span class="sd">            aws_secret_access_key:</span>
<span class="sd">                An AWS secret access key granted to the bucket where the file is located. Not</span>
<span class="sd">                required if keys are stored as environmental variables.</span>
<span class="sd">            bucket_region: str</span>
<span class="sd">                The AWS region that the bucket is located in. This should be provided if the</span>
<span class="sd">                Redshift cluster is located in a different region from the temp bucket.</span>

<span class="sd">        `Returns`</span>
<span class="sd">            Parsons Table or ``None``</span>
<span class="sd">                See :ref:`parsons-table` for output options.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_table_precheck</span><span class="p">(</span><span class="n">connection</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">if_exists</span><span class="p">):</span>
                <span class="c1"># Grab the object from s3</span>
                <span class="kn">from</span> <span class="nn">parsons.aws.s3</span> <span class="kn">import</span> <span class="n">S3</span>
                <span class="n">s3</span> <span class="o">=</span> <span class="n">S3</span><span class="p">(</span><span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">aws_access_key_id</span><span class="p">,</span>
                        <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">aws_secret_access_key</span><span class="p">)</span>

                <span class="n">local_path</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">data_type</span> <span class="o">==</span> <span class="s1">&#39;csv&#39;</span><span class="p">:</span>
                    <span class="n">tbl</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="n">csv_delimiter</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Invalid data type provided&quot;</span><span class="p">)</span>

                <span class="c1"># Create the table</span>
                <span class="n">sql</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_statement</span><span class="p">(</span><span class="n">tbl</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                                            <span class="n">distkey</span><span class="o">=</span><span class="n">distkey</span><span class="p">,</span> <span class="n">sortkey</span><span class="o">=</span><span class="n">sortkey</span><span class="p">,</span>
                                            <span class="n">varchar_max</span><span class="o">=</span><span class="n">varchar_max</span><span class="p">,</span>
                                            <span class="n">columntypes</span><span class="o">=</span><span class="n">columntypes</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s1"> created.&#39;</span><span class="p">)</span>

            <span class="c1"># Copy the table</span>
            <span class="n">copy_sql</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_statement</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">manifest</span><span class="o">=</span><span class="n">manifest</span><span class="p">,</span>
                                           <span class="n">data_type</span><span class="o">=</span><span class="n">data_type</span><span class="p">,</span> <span class="n">csv_delimiter</span><span class="o">=</span><span class="n">csv_delimiter</span><span class="p">,</span>
                                           <span class="n">compression</span><span class="o">=</span><span class="n">compression</span><span class="p">,</span> <span class="n">max_errors</span><span class="o">=</span><span class="n">max_errors</span><span class="p">,</span>
                                           <span class="n">statupdate</span><span class="o">=</span><span class="n">statupdate</span><span class="p">,</span> <span class="n">compupdate</span><span class="o">=</span><span class="n">compupdate</span><span class="p">,</span>
                                           <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">aws_access_key_id</span><span class="p">,</span>
                                           <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">aws_secret_access_key</span><span class="p">,</span>
                                           <span class="n">ignoreheader</span><span class="o">=</span><span class="n">ignoreheader</span><span class="p">,</span> <span class="n">acceptanydate</span><span class="o">=</span><span class="n">acceptanydate</span><span class="p">,</span>
                                           <span class="n">emptyasnull</span><span class="o">=</span><span class="n">emptyasnull</span><span class="p">,</span> <span class="n">blanksasnull</span><span class="o">=</span><span class="n">blanksasnull</span><span class="p">,</span>
                                           <span class="n">nullas</span><span class="o">=</span><span class="n">nullas</span><span class="p">,</span> <span class="n">acceptinvchars</span><span class="o">=</span><span class="n">acceptinvchars</span><span class="p">,</span>
                                           <span class="n">truncatecolumns</span><span class="o">=</span><span class="n">truncatecolumns</span><span class="p">,</span>
                                           <span class="n">specifycols</span><span class="o">=</span><span class="n">specifycols</span><span class="p">,</span>
                                           <span class="n">dateformat</span><span class="o">=</span><span class="n">dateformat</span><span class="p">,</span> <span class="n">timeformat</span><span class="o">=</span><span class="n">timeformat</span><span class="p">,</span>
                                           <span class="n">bucket_region</span><span class="o">=</span><span class="n">bucket_region</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">copy_sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data copied to </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tbl</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="s1">&#39;fail&#39;</span><span class="p">,</span> <span class="n">max_errors</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">distkey</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">sortkey</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">statupdate</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">compupdate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">acceptanydate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">emptyasnull</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">blanksasnull</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nullas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">acceptinvchars</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">dateformat</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">timeformat</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">varchar_max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">truncatecolumns</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">columntypes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">specifycols</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">alter_table</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iam_role</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">cleanup_s3_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">template_table</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temp_bucket_region</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copy a :ref:`parsons-table` to Redshift.</span>

<span class="sd">        `Args:`</span>
<span class="sd">            tbl: obj</span>
<span class="sd">                A Parsons Table.</span>
<span class="sd">            table_name: str</span>
<span class="sd">                The destination table name (ex. ``my_schema.my_table``).</span>
<span class="sd">            if_exists: str</span>
<span class="sd">                If the table already exists, either ``fail``, ``append``, ``drop``</span>
<span class="sd">                or ``truncate`` the table.</span>
<span class="sd">            max_errors: int</span>
<span class="sd">                The maximum number of rows that can error and be skipped before</span>
<span class="sd">                the job fails.</span>
<span class="sd">            distkey: str</span>
<span class="sd">                The column name of the distkey</span>
<span class="sd">            sortkey: str</span>
<span class="sd">                The column name of the sortkey</span>
<span class="sd">            padding: float</span>
<span class="sd">                A percentage padding to add to varchar columns if creating a new table. This is</span>
<span class="sd">                helpful to add a buffer for future copies in which the data might be wider.</span>
<span class="sd">            varchar_max: list</span>
<span class="sd">                A list of columns in which to set the width of the varchar column to 65,535</span>
<span class="sd">                characters.</span>
<span class="sd">            statupate: boolean</span>
<span class="sd">                Governs automatic computation and refresh of optimizer statistics at the end</span>
<span class="sd">                of a successful COPY command.</span>
<span class="sd">            compupdate: boolean</span>
<span class="sd">                Controls whether compression encodings are automatically applied during a COPY.</span>
<span class="sd">            acceptanydate: boolean</span>
<span class="sd">                Allows any date format, including invalid formats such as 00/00/00 00:00:00, to be</span>
<span class="sd">                loaded without generating an error.</span>
<span class="sd">            emptyasnull: boolean</span>
<span class="sd">                Indicates that Amazon Redshift should load empty char and varchar fields</span>
<span class="sd">                as ``NULL``.</span>
<span class="sd">            blanksasnull: boolean</span>
<span class="sd">                Loads blank varchar fields, which consist of only white space characters,</span>
<span class="sd">                as ``NULL``.</span>
<span class="sd">            nullas: str</span>
<span class="sd">                Loads fields that match string as NULL</span>
<span class="sd">            acceptinvchars: boolean</span>
<span class="sd">                Enables loading of data into VARCHAR columns even if the data contains</span>
<span class="sd">                invalid UTF-8 characters.</span>
<span class="sd">            dateformat: str</span>
<span class="sd">                Set the date format. Defaults to ``auto``.</span>
<span class="sd">            timeformat: str</span>
<span class="sd">                Set the time format. Defaults to ``auto``.</span>
<span class="sd">            truncatecolumns: boolean</span>
<span class="sd">                If the table already exists, truncates data in columns to the appropriate number</span>
<span class="sd">                of characters so that it fits the column specification. Applies only to columns</span>
<span class="sd">                with a VARCHAR or CHAR data type, and rows 4 MB or less in size.</span>
<span class="sd">            columntypes: dict</span>
<span class="sd">                Optional map of column name to redshift column type, overriding the usual type</span>
<span class="sd">                inference. You only specify the columns you want to override, eg.</span>
<span class="sd">                ``columntypes={&#39;phone&#39;: &#39;varchar(12)&#39;, &#39;age&#39;: &#39;int&#39;})``.</span>
<span class="sd">            specifycols: boolean</span>
<span class="sd">                Adds a column list to the Redshift `COPY` command, allowing for the source table</span>
<span class="sd">                in an append to have the columnns out of order, and to have fewer columns with any</span>
<span class="sd">                leftover target table columns filled in with the `DEFAULT` value.</span>

<span class="sd">                This will fail if all of the source table&#39;s columns do not match a column in the</span>
<span class="sd">                target table. This will also fail if the target table has an `IDENTITY`</span>
<span class="sd">                column and that column name is among the source table&#39;s columns.</span>
<span class="sd">            alter_table: boolean</span>
<span class="sd">                Will check if the target table varchar widths are wide enough to copy in the</span>
<span class="sd">                table data. If not, will attempt to alter the table to make it wide enough. This</span>
<span class="sd">                will not work with tables that have dependent views.</span>
<span class="sd">            aws_access_key_id:</span>
<span class="sd">                An AWS access key granted to the bucket where the file is located. Not required</span>
<span class="sd">                if keys are stored as environmental variables.</span>
<span class="sd">            aws_secret_access_key:</span>
<span class="sd">                An AWS secret access key granted to the bucket where the file is located. Not</span>
<span class="sd">                required if keys are stored as environmental variables.</span>
<span class="sd">            iam_role: str</span>
<span class="sd">                An AWS IAM Role ARN string; an alternative credential for the COPY command</span>
<span class="sd">                from Redshift to S3. The IAM role must have been assigned to the Redshift</span>
<span class="sd">                instance and have access to the S3 bucket.</span>
<span class="sd">            cleanup_s3_file: boolean</span>
<span class="sd">                The s3 upload is removed by default on cleanup. You can set to False for debugging.</span>
<span class="sd">            template_table: str</span>
<span class="sd">                Instead of specifying columns, columntypes, and/or inference, if there</span>
<span class="sd">                is a pre-existing table that has the same columns/types, then use the template_table</span>
<span class="sd">                table name as the schema for the new table.</span>
<span class="sd">                Unless you set specifycols=False explicitly, a template_table will set it to True</span>
<span class="sd">            temp_bucket_region: str</span>
<span class="sd">                The AWS region that the temp bucket (specified by the TEMP_S3_BUCKET environment</span>
<span class="sd">                variable) is located in. This should be provided if the Redshift cluster is located</span>
<span class="sd">                in a different region from the temp bucket.</span>

<span class="sd">        `Returns`</span>
<span class="sd">            Parsons Table or ``None``</span>
<span class="sd">                See :ref:`parsons-table` for output options.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Specify the columns for a copy statement.</span>
        <span class="k">if</span> <span class="n">specifycols</span> <span class="ow">or</span> <span class="p">(</span><span class="n">specifycols</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">template_table</span><span class="p">):</span>
            <span class="n">cols</span> <span class="o">=</span> <span class="n">tbl</span><span class="o">.</span><span class="n">columns</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cols</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>

            <span class="c1"># Check to see if the table exists. If it does not or if_exists = drop, then</span>
            <span class="c1"># create the new table.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_table_precheck</span><span class="p">(</span><span class="n">connection</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">if_exists</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">template_table</span><span class="p">:</span>
                    <span class="c1"># Copy the schema from the template table</span>
                    <span class="n">sql</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;CREATE TABLE </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s1"> (LIKE </span><span class="si">{</span><span class="n">template_table</span><span class="si">}</span><span class="s1">)&#39;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">sql</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_statement</span><span class="p">(</span><span class="n">tbl</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
                                                <span class="n">distkey</span><span class="o">=</span><span class="n">distkey</span><span class="p">,</span> <span class="n">sortkey</span><span class="o">=</span><span class="n">sortkey</span><span class="p">,</span>
                                                <span class="n">varchar_max</span><span class="o">=</span><span class="n">varchar_max</span><span class="p">,</span>
                                                <span class="n">columntypes</span><span class="o">=</span><span class="n">columntypes</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s1"> created.&#39;</span><span class="p">)</span>

            <span class="c1"># If alter_table is True, then alter table if the table column widths</span>
            <span class="c1"># are wider than the existing table.</span>
            <span class="k">if</span> <span class="n">alter_table</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">alter_varchar_column_widths</span><span class="p">(</span><span class="n">tbl</span><span class="p">,</span> <span class="n">table_name</span><span class="p">)</span>

            <span class="c1"># Upload the table to S3</span>
            <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temp_s3_copy</span><span class="p">(</span><span class="n">tbl</span><span class="p">,</span> <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">aws_access_key_id</span><span class="p">,</span>
                                    <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">aws_secret_access_key</span><span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Copy to Redshift database.</span>
                <span class="n">copy_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_errors&#39;</span><span class="p">:</span> <span class="n">max_errors</span><span class="p">,</span>
                             <span class="s1">&#39;ignoreheader&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                             <span class="s1">&#39;statupdate&#39;</span><span class="p">:</span> <span class="n">statupdate</span><span class="p">,</span>
                             <span class="s1">&#39;compupdate&#39;</span><span class="p">:</span> <span class="n">compupdate</span><span class="p">,</span>
                             <span class="s1">&#39;acceptanydate&#39;</span><span class="p">:</span> <span class="n">acceptanydate</span><span class="p">,</span>
                             <span class="s1">&#39;dateformat&#39;</span><span class="p">:</span> <span class="n">dateformat</span><span class="p">,</span>
                             <span class="s1">&#39;timeformat&#39;</span><span class="p">:</span> <span class="n">timeformat</span><span class="p">,</span>
                             <span class="s1">&#39;blanksasnull&#39;</span><span class="p">:</span> <span class="n">blanksasnull</span><span class="p">,</span>
                             <span class="s1">&#39;nullas&#39;</span><span class="p">:</span> <span class="n">nullas</span><span class="p">,</span>
                             <span class="s1">&#39;emptyasnull&#39;</span><span class="p">:</span> <span class="n">emptyasnull</span><span class="p">,</span>
                             <span class="s1">&#39;acceptinvchars&#39;</span><span class="p">:</span> <span class="n">acceptinvchars</span><span class="p">,</span>
                             <span class="s1">&#39;truncatecolumns&#39;</span><span class="p">:</span> <span class="n">truncatecolumns</span><span class="p">,</span>
                             <span class="s1">&#39;specifycols&#39;</span><span class="p">:</span> <span class="n">cols</span><span class="p">,</span>
                             <span class="s1">&#39;aws_access_key_id&#39;</span><span class="p">:</span> <span class="n">aws_access_key_id</span><span class="p">,</span>
                             <span class="s1">&#39;aws_secret_access_key&#39;</span><span class="p">:</span> <span class="n">aws_secret_access_key</span><span class="p">,</span>
                             <span class="s1">&#39;compression&#39;</span><span class="p">:</span> <span class="s1">&#39;gzip&#39;</span><span class="p">,</span>
                             <span class="s1">&#39;bucket_region&#39;</span><span class="p">:</span> <span class="n">temp_bucket_region</span><span class="p">}</span>

                <span class="c1"># Copy from S3 to Redshift</span>
                <span class="n">sql</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_statement</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">s3_temp_bucket</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="o">**</span><span class="n">copy_args</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Copy SQL command: </span><span class="si">{</span><span class="n">sql</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Data copied to </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

            <span class="c1"># Clean up the S3 bucket.</span>
            <span class="k">finally</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">and</span> <span class="n">cleanup_s3_file</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">temp_s3_delete</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">unload</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sql</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">key_prefix</span><span class="p">,</span> <span class="n">manifest</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;|&#39;</span><span class="p">,</span>
               <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;gzip&#39;</span><span class="p">,</span> <span class="n">add_quotes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">null_as</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">escape</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_file_size</span><span class="o">=</span><span class="s1">&#39;6.2 GB&#39;</span><span class="p">,</span> <span class="n">aws_region</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Unload Redshift data to S3 Bucket. This is a more efficient method than running a query</span>
<span class="sd">        to export data as it can export in parallel and directly into an S3 bucket. Consider</span>
<span class="sd">        using this for exports of 10MM or more rows.</span>

<span class="sd">        sql: str</span>
<span class="sd">            The SQL string to execute to generate the data to unload.</span>
<span class="sd">        buckey: str</span>
<span class="sd">           The destination S3 bucket</span>
<span class="sd">        key_prefix: str</span>
<span class="sd">            The prefix of the key names that will be written</span>
<span class="sd">        manifest: boolean</span>
<span class="sd">            Creates a manifest file that explicitly lists details for the data files</span>
<span class="sd">            that are created by the UNLOAD process.</span>
<span class="sd">        header: boolean</span>
<span class="sd">            Adds a header line containing column names at the top of each output file.</span>
<span class="sd">        delimiter: str</span>
<span class="sd">            Specificies the character used to separate fields. Defaults to &#39;|&#39;.</span>
<span class="sd">        compression: str</span>
<span class="sd">            One of ``gzip``, ``bzip2`` or ``None``. Unloads data to one or more compressed</span>
<span class="sd">            files per slice. Each resulting file is appended with a ``.gz`` or ``.bz2`` extension.</span>
<span class="sd">        add_quotes: boolean</span>
<span class="sd">            Places quotation marks around each unloaded data field, so that Amazon Redshift</span>
<span class="sd">            can unload data values that contain the delimiter itself.</span>
<span class="sd">        null_as: str</span>
<span class="sd">            Specifies a string that represents a null value in unload files. If this option is</span>
<span class="sd">            not specified, null values are unloaded as zero-length strings for delimited output.</span>
<span class="sd">        escape: boolean</span>
<span class="sd">            For CHAR and VARCHAR columns in delimited unload files, an escape character (\) is</span>
<span class="sd">            placed before every linefeed, carriage return, escape characters and delimiters.</span>
<span class="sd">        allow_overwrite: boolean</span>
<span class="sd">            If ``True``, will overwrite existing files, including the manifest file. If ``False``</span>
<span class="sd">            will fail.</span>
<span class="sd">        parallel: boolean</span>
<span class="sd">            By default, UNLOAD writes data in parallel to multiple files, according to the number</span>
<span class="sd">            of slices in the cluster. The default option is ON or TRUE. If PARALLEL is OFF or</span>
<span class="sd">            FALSE, UNLOAD writes to one or more data files serially, sorted absolutely according</span>
<span class="sd">            to the ORDER BY clause, if one is used.</span>
<span class="sd">        max_file_size: str</span>
<span class="sd">            The maximum size of files UNLOAD creates in Amazon S3. Specify a decimal value between</span>
<span class="sd">            5 MB and 6.2 GB.</span>
<span class="sd">        region: str</span>
<span class="sd">            The AWS Region where the target Amazon S3 bucket is located. REGION is required for</span>
<span class="sd">            UNLOAD to an Amazon S3 bucket that is not in the same AWS Region as the Amazon Redshift</span>
<span class="sd">            cluster.</span>
<span class="sd">        aws_access_key_id:</span>
<span class="sd">            An AWS access key granted to the bucket where the file is located. Not required</span>
<span class="sd">            if keys are stored as environmental variables.</span>
<span class="sd">        aws_secret_access_key:</span>
<span class="sd">            An AWS secret access key granted to the bucket where the file is located. Not</span>
<span class="sd">            required if keys are stored as environmental variables.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># NOQA W605</span>

        <span class="c1"># The sql query is provided between single quotes, therefore single</span>
        <span class="c1"># quotes within the actual query must be escaped.</span>
        <span class="c1"># https://docs.aws.amazon.com/redshift/latest/dg/r_UNLOAD.html#unload-parameters</span>
        <span class="n">sql</span> <span class="o">=</span> <span class="n">sql</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;&#39;&#39;&quot;</span><span class="p">)</span>

        <span class="n">statement</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                     UNLOAD (&#39;</span><span class="si">{</span><span class="n">sql</span><span class="si">}</span><span class="s2">&#39;) to &#39;s3://</span><span class="si">{</span><span class="n">bucket</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">key_prefix</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2"></span>
<span class="s2">                     </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">get_creds</span><span class="p">(</span><span class="n">aws_access_key_id</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2"></span>
<span class="s2">                     PARALLEL </span><span class="si">{</span><span class="n">parallel</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2"></span>
<span class="s2">                     MAXFILESIZE </span><span class="si">{</span><span class="n">max_file_size</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                     &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">manifest</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="s2">&quot;MANIFEST </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">header</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="s2">&quot;HEADER </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">delimiter</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;DELIMITER as &#39;</span><span class="si">{</span><span class="n">delimiter</span><span class="si">}</span><span class="s2">&#39; </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">compression</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">compression</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">add_quotes</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="s2">&quot;ADDQUOTES </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">null_as</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;NULL </span><span class="si">{</span><span class="n">null_as</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">escape</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="s2">&quot;ESCAPE </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">allow_overwrite</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="s2">&quot;ALLOWOVERWRITE </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">aws_region</span><span class="p">:</span>
            <span class="n">statement</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;REGION </span><span class="si">{</span><span class="n">aws_region</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Unloading data to s3://</span><span class="si">{</span><span class="n">bucket</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">key_prefix</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">statement</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">statement</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate_manifest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buckets</span><span class="p">,</span> <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">mandatory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">manifest_bucket</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">manifest_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">path</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Given a list of S3 buckets, generate a manifest file (JSON format). A manifest file</span>
<span class="sd">        allows you to copy multiple files into a single table at once. Once the manifest is</span>
<span class="sd">        generated, you can pass it with the :func:`~parsons.redshift.Redshift.copy_s3` method.</span>

<span class="sd">        AWS keys are not required if ``AWS_ACCESS_KEY_ID`` and</span>
<span class="sd">        ``AWS_SECRET_ACCESS_KEY`` environmental variables set.</span>

<span class="sd">        `Args:`</span>

<span class="sd">            buckets: list or str</span>
<span class="sd">                A list of buckets or single bucket from which to generate manifest</span>
<span class="sd">            aws_access_key_id: str</span>
<span class="sd">                AWS access key id to access S3 bucket</span>
<span class="sd">            aws_secret_access_key: str</span>
<span class="sd">                AWS secret access key to access S3 bucket</span>
<span class="sd">            mandatory: boolean</span>
<span class="sd">                The mandatory flag indicates whether the Redshift COPY should</span>
<span class="sd">                terminate if the file does not exist.</span>
<span class="sd">            prefix: str</span>
<span class="sd">                Optional filter for key prefixes</span>
<span class="sd">            manifest_bucket: str</span>
<span class="sd">                Optional bucket to write manifest file.</span>
<span class="sd">            manifest_key: str</span>
<span class="sd">                Optional key name for S3 bucket to write file</span>

<span class="sd">        `Returns:`</span>
<span class="sd">            ``dict`` of manifest</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="kn">from</span> <span class="nn">parsons.aws</span> <span class="kn">import</span> <span class="n">S3</span>
        <span class="n">s3</span> <span class="o">=</span> <span class="n">S3</span><span class="p">(</span><span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">aws_access_key_id</span><span class="p">,</span>
                <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">aws_secret_access_key</span><span class="p">)</span>

        <span class="c1"># Deal with a single bucket being passed, rather than list.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">buckets</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">buckets</span> <span class="o">=</span> <span class="p">[</span><span class="n">buckets</span><span class="p">]</span>

        <span class="c1"># Generate manifest file</span>
        <span class="n">manifest</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;entries&#39;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="k">for</span> <span class="n">bucket</span> <span class="ow">in</span> <span class="n">buckets</span><span class="p">:</span>

            <span class="c1"># Retrieve list of files in bucket</span>
            <span class="n">key_list</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">list_keys</span><span class="p">(</span><span class="n">bucket</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">key_list</span><span class="p">:</span>
                <span class="n">manifest</span><span class="p">[</span><span class="s1">&#39;entries&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                    <span class="s1">&#39;url&#39;</span><span class="p">:</span> <span class="s1">&#39;/&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;s3:/&#39;</span><span class="p">,</span> <span class="n">bucket</span><span class="p">,</span> <span class="n">key</span><span class="p">]),</span>
                    <span class="s1">&#39;mandatory&#39;</span><span class="p">:</span> <span class="n">mandatory</span>
                <span class="p">})</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Manifest generated.&#39;</span><span class="p">)</span>

        <span class="c1"># Save the file to s3 bucket if provided</span>
        <span class="k">if</span> <span class="n">manifest_key</span> <span class="ow">and</span> <span class="n">manifest_bucket</span><span class="p">:</span>
            <span class="c1"># Dump the manifest to a temp JSON file</span>
            <span class="n">manifest_path</span> <span class="o">=</span> <span class="n">files</span><span class="o">.</span><span class="n">create_temp_file</span><span class="p">()</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">manifest_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">manifest_file_obj</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">manifest</span><span class="p">,</span> <span class="n">manifest_file_obj</span><span class="p">,</span> <span class="n">sort_keys</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

            <span class="c1"># Upload the file to S3</span>
            <span class="n">s3</span><span class="o">.</span><span class="n">put_file</span><span class="p">(</span><span class="n">manifest_bucket</span><span class="p">,</span> <span class="n">manifest_key</span><span class="p">,</span> <span class="n">manifest_path</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Manifest saved to s3://</span><span class="si">{</span><span class="n">manifest_bucket</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">manifest_key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">manifest</span>

    <span class="k">def</span> <span class="nf">upsert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table_obj</span><span class="p">,</span> <span class="n">target_table</span><span class="p">,</span> <span class="n">primary_key</span><span class="p">,</span> <span class="n">vacuum</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">distinct_check</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">cleanup_temp_table</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alter_table</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">copy_args</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Preform an upsert on an existing table. An upsert is a function in which records</span>
<span class="sd">        in a table are updated and inserted at the same time. Unlike other SQL databases,</span>
<span class="sd">        it does not exist natively in Redshift.</span>

<span class="sd">        `Args:`</span>
<span class="sd">            table_obj: obj</span>
<span class="sd">                A Parsons table object</span>
<span class="sd">            target_table: str</span>
<span class="sd">                The schema and table name to upsert</span>
<span class="sd">            primary_key: str or list</span>
<span class="sd">                The primary key column(s) of the target table</span>
<span class="sd">            vacuum: boolean</span>
<span class="sd">                Re-sorts rows and reclaims space in the specified table. You must be a table owner</span>
<span class="sd">                or super user to effectively vacuum a table, however the method will not fail</span>
<span class="sd">                if you lack these priviledges.</span>
<span class="sd">            distinct_check: boolean</span>
<span class="sd">                Check if the primary key column is distinct. Raise error if not.</span>
<span class="sd">            cleanup_temp_table: boolean</span>
<span class="sd">                A temp table is dropped by default on cleanup. You can set to False for debugging.</span>
<span class="sd">            \**copy_args: kwargs</span>
<span class="sd">                See :func:`~parsons.databases.Redshift.copy`` for options.</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># noqa: W605</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">table_exists</span><span class="p">(</span><span class="n">target_table</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Target table does not exist. Copying into newly </span><span class="se">\</span>
<span class="s1">                         created target table.&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">table_obj</span><span class="p">,</span> <span class="n">target_table</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">alter_table</span><span class="p">:</span>
            <span class="c1"># Make target table column widths match incoming table, if necessary</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alter_varchar_column_widths</span><span class="p">(</span><span class="n">table_obj</span><span class="p">,</span> <span class="n">target_table</span><span class="p">)</span>

        <span class="n">noise</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">random</span><span class="o">.</span><span class="n">randrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span><span class="si">:</span><span class="s1">04</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span>
        <span class="n">date_stamp</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y%m</span><span class="si">%d</span><span class="s1">_%H%M&#39;</span><span class="p">)</span>
        <span class="c1"># Generate a temp table like &quot;table_tmp_20200210_1230_14212&quot;</span>
        <span class="n">staging_tbl</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">_stg_</span><span class="si">{}</span><span class="s1">_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">target_table</span><span class="p">,</span> <span class="n">date_stamp</span><span class="p">,</span> <span class="n">noise</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">primary_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">primary_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">primary_key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">primary_keys</span> <span class="o">=</span> <span class="n">primary_key</span>

        <span class="k">if</span> <span class="n">distinct_check</span><span class="p">:</span>
            <span class="n">primary_keys_statement</span> <span class="o">=</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">primary_keys</span><span class="p">)</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;&#39;&#39;</span>
<span class="s1">                select (</span>
<span class="s1">                    select count(*)</span>
<span class="s1">                    from </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s1"></span>
<span class="s1">                ) - (</span>
<span class="s1">                    SELECT COUNT(*) from (</span>
<span class="s1">                        select distinct </span><span class="si">{</span><span class="n">primary_keys_statement</span><span class="si">}</span><span class="s1"></span>
<span class="s1">                        from </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s1"></span>
<span class="s1">                    )</span>
<span class="s1">                ) as total_count</span>
<span class="s1">            &#39;&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span>
            <span class="k">if</span> <span class="n">diff</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Primary key column contains duplicate values.&#39;</span><span class="p">)</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Copy to a staging table</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Building staging table: </span><span class="si">{</span><span class="n">staging_tbl</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="s1">&#39;compupdate&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">copy_args</span><span class="p">:</span>
                    <span class="c1"># Especially with a lot of columns, compupdate=True can</span>
                    <span class="c1"># cause a lot of processing/analysis by Redshift before upload.</span>
                    <span class="c1"># Since this is a temporary table, setting compression for each</span>
                    <span class="c1"># column is not impactful barely impactful</span>
                    <span class="c1"># https://docs.aws.amazon.com/redshift/latest/dg/c_Loading_tables_auto_compress.html</span>
                    <span class="n">copy_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">copy_args</span><span class="p">,</span> <span class="n">compupdate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">table_obj</span><span class="p">,</span> <span class="n">staging_tbl</span><span class="p">,</span>
                          <span class="n">template_table</span><span class="o">=</span><span class="n">target_table</span><span class="p">,</span>
                          <span class="n">alter_table</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># We just did our own alter table above</span>
                          <span class="o">**</span><span class="n">copy_args</span><span class="p">)</span>

                <span class="n">staging_table_name</span> <span class="o">=</span> <span class="n">staging_tbl</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">target_table_name</span> <span class="o">=</span> <span class="n">target_table</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

                <span class="c1"># Delete rows</span>
                <span class="n">comparisons</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">staging_table_name</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">primary_key</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">target_table_name</span><span class="si">}</span><span class="s1">.</span><span class="si">{</span><span class="n">primary_key</span><span class="si">}</span><span class="s1">&#39;</span>
                    <span class="k">for</span> <span class="n">primary_key</span> <span class="ow">in</span> <span class="n">primary_keys</span>
                <span class="p">]</span>
                <span class="n">where_clause</span> <span class="o">=</span> <span class="s1">&#39; and &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">comparisons</span><span class="p">)</span>

                <span class="n">sql</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                       DELETE FROM </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                       USING </span><span class="si">{</span><span class="n">staging_tbl</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                       WHERE </span><span class="si">{</span><span class="n">where_clause</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                       &quot;&quot;&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Target rows deleted from </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

                <span class="c1"># Insert rows</span>
                <span class="c1"># ALTER TABLE APPEND would be more efficient, but you can&#39;t run it in a</span>
                <span class="c1"># transaction block. It&#39;s worth the performance hit to not commit until the</span>
                <span class="c1"># end.</span>
                <span class="n">sql</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                       INSERT INTO </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s2"></span>
<span class="s2">                       SELECT * FROM </span><span class="si">{</span><span class="n">staging_tbl</span><span class="si">}</span><span class="s2">;</span>
<span class="s2">                       &quot;&quot;&quot;</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Target rows inserted to </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="k">finally</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">cleanup_temp_table</span><span class="p">:</span>
                    <span class="c1"># Drop the staging table</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DROP TABLE IF EXISTS </span><span class="si">{</span><span class="n">staging_tbl</span><span class="si">}</span><span class="s2">;&quot;</span><span class="p">,</span>
                                               <span class="n">connection</span><span class="p">,</span> <span class="n">commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">staging_tbl</span><span class="si">}</span><span class="s1"> staging table dropped.&#39;</span><span class="p">)</span>

        <span class="c1"># Vacuum table. You must commit when running this type of transaction.</span>
        <span class="k">if</span> <span class="n">vacuum</span><span class="p">:</span>
            <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>
                <span class="n">connection</span><span class="o">.</span><span class="n">set_session</span><span class="p">(</span><span class="n">autocommit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;VACUUM </span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s1">;&#39;</span><span class="p">,</span> <span class="n">connection</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">target_table</span><span class="si">}</span><span class="s1"> vacuumed.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">alter_varchar_column_widths</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tbl</span><span class="p">,</span> <span class="n">table_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Alter the width of a varchar columns in a Redshift table to match the widths</span>
<span class="sd">        of a Parsons table. The columns are matched by column name and not their</span>
<span class="sd">        index.</span>

<span class="sd">        `Args:`</span>
<span class="sd">            tbl: obj</span>
<span class="sd">                A Parsons table</span>
<span class="sd">            table_name:</span>
<span class="sd">                The target table name (e.g. ``my_schema.my_table``)</span>
<span class="sd">        `Returns:`</span>
<span class="sd">            ``None``</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Make the Parsons table column names match valid Redshift names</span>
        <span class="n">tbl</span><span class="o">.</span><span class="n">table</span> <span class="o">=</span> <span class="n">petl</span><span class="o">.</span><span class="n">setheader</span><span class="p">(</span><span class="n">tbl</span><span class="o">.</span><span class="n">table</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">column_name_validate</span><span class="p">(</span><span class="n">tbl</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>

        <span class="c1"># Create a list of column names and max width for string values.</span>
        <span class="n">pc</span> <span class="o">=</span> <span class="p">{</span><span class="n">c</span><span class="p">:</span> <span class="n">tbl</span><span class="o">.</span><span class="n">get_column_max_width</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tbl</span><span class="o">.</span><span class="n">columns</span><span class="p">}</span>

        <span class="c1"># Determine the max width of the varchar columns in the Redshift table</span>
        <span class="n">s</span><span class="p">,</span> <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split_full_table_name</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>
        <span class="n">cols</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_columns</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
        <span class="n">rc</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="s1">&#39;max_length&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">cols</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="s1">&#39;data_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;character varying&#39;</span><span class="p">}</span> <span class="c1"># noqa: E501, E261</span>

        <span class="c1"># Figure out if any of the destination table varchar columns are smaller than the</span>
        <span class="c1"># associated Parsons table columns. If they are, then alter column types to expand</span>
        <span class="c1"># their width.</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">rc</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">pc</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
            <span class="k">if</span> <span class="n">rc</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">pc</span><span class="p">[</span><span class="n">c</span><span class="p">]:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s1"> not wide enough. Expanding column width.&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">alter_table_column_type</span><span class="p">(</span><span class="n">table_name</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="s1">&#39;varchar&#39;</span><span class="p">,</span> <span class="n">varchar_width</span><span class="o">=</span><span class="n">pc</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">alter_table_column_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table_name</span><span class="p">,</span> <span class="n">column_name</span><span class="p">,</span> <span class="n">data_type</span><span class="p">,</span> <span class="n">varchar_width</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Alter a column type of an existing table.</span>

<span class="sd">        table_name: str</span>
<span class="sd">            The table name (ex. ``my_schema.my_table``).</span>
<span class="sd">        column_name: str</span>
<span class="sd">            The target column name</span>
<span class="sd">        data_type: str</span>
<span class="sd">            A valid Redshift data type to alter the table to.</span>
<span class="sd">        varchar_width:</span>
<span class="sd">            The new width of the column if of type varchar.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sql</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;ALTER TABLE </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2"> ALTER COLUMN </span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s2"> TYPE </span><span class="si">{</span><span class="n">data_type</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="n">varchar_width</span><span class="p">:</span>
            <span class="n">sql</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="n">varchar_width</span><span class="si">}</span><span class="s2">)&quot;</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="p">()</span> <span class="k">as</span> <span class="n">connection</span><span class="p">:</span>
            <span class="n">connection</span><span class="o">.</span><span class="n">set_session</span><span class="p">(</span><span class="n">autocommit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">query_with_connection</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">connection</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Altered </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s1"> </span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s1">.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">table</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table_name</span><span class="p">):</span>
        <span class="c1"># Return a Redshift table object</span>

        <span class="k">return</span> <span class="n">RedshiftTable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">table_name</span><span class="p">)</span></div>


<span class="k">class</span> <span class="nc">RedshiftTable</span><span class="p">(</span><span class="n">BaseTable</span><span class="p">):</span>
    <span class="c1"># Redshift table object.</span>

    <span class="k">pass</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, The Movement Cooperative

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../../_static/language_data.js"></script>
    

  

  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>