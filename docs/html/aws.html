

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Amazon Web Services &mdash; Parsons 0.5 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Azure: Blob Storage" href="azure.html" />
    <link rel="prev" title="Airtable" href="airtable.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> Parsons
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Integrations</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="action_kit.html">ActionKit</a></li>
<li class="toctree-l1"><a class="reference internal" href="action_network.html">Action Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="airtable.html">Airtable</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Amazon Web Services</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#lambda">Lambda</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#api">API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#s3">S3</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quickstart">QuickStart</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id3">API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#redshift">Redshift</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id5">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id7">Quickstart</a></li>
<li class="toctree-l3"><a class="reference internal" href="#core-api">Core API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#table-and-view-api">Table and View API</a></li>
<li class="toctree-l3"><a class="reference internal" href="#schema-api">Schema API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="azure.html">Azure: Blob Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="bill_com.html">Bill.com</a></li>
<li class="toctree-l1"><a class="reference internal" href="bloomerang.html">Bloomerang</a></li>
<li class="toctree-l1"><a class="reference internal" href="box.html">Box</a></li>
<li class="toctree-l1"><a class="reference internal" href="braintree.html">Braintree</a></li>
<li class="toctree-l1"><a class="reference internal" href="civis.html">Civis</a></li>
<li class="toctree-l1"><a class="reference internal" href="copper.html">Copper</a></li>
<li class="toctree-l1"><a class="reference internal" href="crowdtangle.html">CrowdTangle</a></li>
<li class="toctree-l1"><a class="reference internal" href="databases.html">Databases</a></li>
<li class="toctree-l1"><a class="reference internal" href="facebook_ads.html">FacebookAds</a></li>
<li class="toctree-l1"><a class="reference internal" href="freshdesk.html">Freshdesk</a></li>
<li class="toctree-l1"><a class="reference internal" href="github.html">GitHub</a></li>
<li class="toctree-l1"><a class="reference internal" href="google.html">Google</a></li>
<li class="toctree-l1"><a class="reference internal" href="hustle.html">Hustle</a></li>
<li class="toctree-l1"><a class="reference internal" href="mailchimp.html">Mailchimp</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobilize_america.html">Mobilize America</a></li>
<li class="toctree-l1"><a class="reference internal" href="newmode.html">New/Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="ngpvan.html">NGPVAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="pdi.html">PDI</a></li>
<li class="toctree-l1"><a class="reference internal" href="p2a.html">Phone2Action</a></li>
<li class="toctree-l1"><a class="reference internal" href="redash.html">Redash</a></li>
<li class="toctree-l1"><a class="reference internal" href="rockthevote.html">Rock the Vote</a></li>
<li class="toctree-l1"><a class="reference internal" href="salesforce.html">Salesforce</a></li>
<li class="toctree-l1"><a class="reference internal" href="sftp.html">SFTP</a></li>
<li class="toctree-l1"><a class="reference internal" href="targetsmart.html">TargetSmart</a></li>
<li class="toctree-l1"><a class="reference internal" href="turbovote.html">TurboVote</a></li>
<li class="toctree-l1"><a class="reference internal" href="twilio.html">Twilio</a></li>
<li class="toctree-l1"><a class="reference internal" href="zoom.html">Zoom</a></li>
</ul>
<p class="caption"><span class="caption-text">Enhancements</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="census_geocoder.html">US Census Geocoder</a></li>
</ul>
<p class="caption"><span class="caption-text">Framework</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="dbsync.html">Database Sync</a></li>
<li class="toctree-l1"><a class="reference internal" href="table.html">Parsons Table</a></li>
<li class="toctree-l1"><a class="reference internal" href="notifications.html">Notifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utilities</a></li>
</ul>
<p class="caption"><span class="caption-text">Contributor Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to Parsons</a></li>
<li class="toctree-l1"><a class="reference internal" href="build_a_connector.html">How to Build a Connector</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Parsons</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Amazon Web Services</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/aws.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="amazon-web-services">
<h1>Amazon Web Services<a class="headerlink" href="#amazon-web-services" title="Permalink to this headline">¶</a></h1>
<div class="section" id="lambda">
<h2>Lambda<a class="headerlink" href="#lambda" title="Permalink to this headline">¶</a></h2>
<div class="section" id="api">
<h3>API<a class="headerlink" href="#api" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="parsons.aws.distribute_task">
<code class="descclassname">parsons.aws.</code><code class="descname">distribute_task</code><span class="sig-paren">(</span><em>table</em>, <em>func_to_run</em>, <em>bucket=None</em>, <em>func_kwargs=None</em>, <em>func_class=None</em>, <em>func_class_kwargs=None</em>, <em>catch=False</em>, <em>group_count=100</em>, <em>storage='s3'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/lambda_distribute.html#distribute_task"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.aws.distribute_task" title="Permalink to this definition">¶</a></dt>
<dd><p>Distribute processing rows in a table across multiple AWS Lambda invocations.</p>
<p>If you are running the processing of a table inside AWS Lambda, then you
are limited by how many rows can be processed within the Lambda’s time limit
(at time-of-writing, maximum 15min).</p>
<p>Based on experience and some napkin math, with
the same data that would allow 1000 rows to be processed inside a single
AWS Lambda instance, this method allows 10 MILLION rows to be processed.</p>
<p>Rather than converting the table to SQS
or other options, the fastest way is to upload the table to S3, and then
invoke multiple Lambda sub-invocations, each of which can be sent a
byte-range of the data in the S3 CSV file for which to process.</p>
<p>Using this method requires some setup. You have three tasks:</p>
<ol class="arabic simple">
<li>Define the function to process rows, the first argument, must take
your table’s data (though only a subset of rows will be passed)
(e.g. <cite>def task_for_distribution(table, **kwargs):</cite>)</li>
<li>Where you would have run <cite>task_for_distribution(my_table, **kwargs)</cite>
instead call <a href="#id1"><span class="problematic" id="id2">`</span></a>distribute_task(my_table, task_for_distribution, func_kwargs=kwargs)
(either setting env var S3_TEMP_BUCKET or passing a bucket= parameter)</li>
<li>Setup your Lambda handler to include <a class="reference internal" href="#parsons.aws.event_command" title="parsons.aws.event_command"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parsons.aws.event_command()</span></code></a>
(or run and deploy your lambda with <a class="reference external" href="https://github.com/Miserlou/Zappa">Zappa</a>)</li>
</ol>
<p>To test locally, include the argument <cite>storage=”local”</cite> which will test
the distribute_task function, but run the task sequentially and in local memory.</p>
<p>A minimalistic example Lambda handler might look something like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">parsons.aws</span> <span class="kn">import</span> <span class="n">event_command</span><span class="p">,</span> <span class="n">distribute_task</span>

<span class="k">def</span> <span class="nf">process_table</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">foo</span><span class="p">,</span> <span class="n">bar</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">table</span><span class="p">:</span>
<span class="hll">        <span class="n">do_sloooooow_thing</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">foo</span><span class="p">,</span> <span class="n">bar</span><span class="p">)</span>
</span><span class="hll">
</span><span class="k">def</span> <span class="nf">handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="c1">## ADD THESE TWO LINES TO TOP OF HANDLER:</span>
    <span class="k">if</span> <span class="n">event_command</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="k">return</span>
    <span class="n">table</span> <span class="o">=</span> <span class="n">FakeDatasource</span><span class="o">.</span><span class="n">load_to_table</span><span class="p">(</span><span class="n">username</span><span class="o">=</span><span class="s1">&#39;123&#39;</span><span class="p">,</span> <span class="n">password</span><span class="o">=</span><span class="s1">&#39;abc&#39;</span><span class="p">)</span>
    <span class="c1"># table is so big that running</span>
    <span class="c1">#   process_table(table, foo=789, bar=&#39;baz&#39;) would timeout</span>
    <span class="c1"># so instead we:</span>
    <span class="n">distribute_task</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">process_table</span><span class="p">,</span>
                    <span class="n">bucket</span><span class="o">=</span><span class="s1">&#39;my-temp-s3-bucket&#39;</span><span class="p">,</span>
                    <span class="n">func_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;foo&#39;</span><span class="p">:</span> <span class="mi">789</span><span class="p">,</span> <span class="s1">&#39;bar&#39;</span><span class="p">:</span> <span class="s1">&#39;baz&#39;</span><span class="p">})</span>
</pre></div>
</div>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table: Parsons Table</dt>
<dd>Table of data you wish to distribute processing across Lambda invocations
of <cite>func_to_run</cite> argument.</dd>
<dt>func_to_run: function</dt>
<dd>The function you want to run whose
first argument will be a subset of table</dd>
<dt>bucket: str</dt>
<dd>The bucket name to use for s3 upload to process the whole table
Not required if you set environment variable <code class="docutils literal notranslate"><span class="pre">S3_TEMP_BUCKET</span></code></dd>
<dt>func_kwargs: dict</dt>
<dd>If the function has other arguments to pass along with <cite>table</cite>
then provide them as a dict here. They must all be JSON-able.</dd>
<dt>func_class: class</dt>
<dd>If the function is a classmethod or function on a class,
then pass the pure class here.
E.g. If you passed <cite>ActionKit.bulk_upload_table</cite>,
then you would pass <cite>ActionKit</cite> here.</dd>
<dt>func_class_kwargs: dict</dt>
<dd>If it is a class function, and the class must be instantiated,
then pass the kwargs to instantiate the class here.
E.g. If you passed <cite>ActionKit.bulk_upload_table</cite> as the function,
then you would pass {‘domain’: …, ‘username’: … etc} here.
This must all be JSON-able data.</dd>
<dt>catch: bool</dt>
<dd>Lambda will retry running an event three times if there’s an
exception – if you want to prevent this, set <cite>catch=True</cite>
and then it will catch any errors and stop retries.
The error will be in CloudWatch logs with string “Distribute Error”
This might be important if row-actions are not idempotent and your
own function might fail causing repeats.</dd>
<dt>group_count: int</dt>
<dd>Set this to how many rows to process with each Lambda invocation (Default: 100)</dd>
<dt>storage: str</dt>
<dd>Debugging option: Defaults to “s3”. To test distribution locally without s3,
set to “local”.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd>Debug information – do not rely on the output, as it will change
depending on how this method is invoked.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.aws.event_command">
<code class="descclassname">parsons.aws.</code><code class="descname">event_command</code><span class="sig-paren">(</span><em>event</em>, <em>context</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/aws_async.html#event_command"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.aws.event_command" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimal shim to add to the top lambda handler function
to enable distributed tasks
In your lambda handler:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">parsons.aws</span> <span class="kn">import</span> <span class="n">event_command</span>

<span class="k">def</span> <span class="nf">handler</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="c1">## ADD THESE TWO LINES TO TOP OF HANDLER:</span>
<span class="hll">    <span class="k">if</span> <span class="n">event_command</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
</span><span class="hll">        <span class="k">return</span>
</span></pre></div>
</div>
<p>The rest of this library is compatible with zappa.async library.
If you have deployed your app with <cite>Zappa &lt;https://github.com/Miserlou/Zappa&gt;</cite>,
then you do NOT need to add this shim.</p>
</dd></dl>

</div>
<p>.. autofunction :: parsons.aws.event_command</p>
</div>
<div class="section" id="s3">
<h2>S3<a class="headerlink" href="#s3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h3>
<p>S3 is Amazon Web Service’s object storage service that allows users to store and access data objects. The Parson’s class is a high level wrapper of the AWS SDK <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/index.html">boto3</a>. It allows users to upload and download files from S3 as well as manipulate buckets.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<dl class="last docutils">
<dt>Authentication</dt>
<dd>Access to S3 is controlled through AWS Identity and Access Management (IAM) users in the <a class="reference external" href="https://aws.amazon.com/console/">AWS Managerment Console</a> . Users can be granted granular access to AWS resources, including S3. IAM users are provisioned keys, which are required to access the S3 class.</dd>
</dl>
</div>
</div>
<div class="section" id="quickstart">
<h3>QuickStart<a class="headerlink" href="#quickstart" title="Permalink to this headline">¶</a></h3>
<p>Instantiate class with credentials.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">parsons</span> <span class="kn">import</span> <span class="n">S3</span>

<span class="c1"># First approach: Use API credentials via environmental variables</span>
<span class="n">s3</span> <span class="o">=</span> <span class="n">S3</span><span class="p">()</span>

<span class="c1"># Second approach: Pass API credentials as arguments</span>
<span class="n">s3</span> <span class="o">=</span> <span class="n">S3</span><span class="p">(</span><span class="n">aws_access_key_id</span><span class="o">=</span><span class="s1">&#39;MY_KEY&#39;</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="s1">&#39;MY_SECRET&#39;</span><span class="p">)</span>

<span class="c1"># Third approach: Use credentials stored in AWS CLI file ~/.aws/credentials</span>
<span class="n">s3</span> <span class="o">=</span> <span class="n">S3</span><span class="p">()</span>
</pre></div>
</div>
<p>You can then call various endpoints:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">parsons</span> <span class="kn">import</span> <span class="n">S3</span><span class="p">,</span> <span class="n">Table</span>

<span class="n">s3</span> <span class="o">=</span> <span class="n">S3</span><span class="p">(</span><span class="n">aws_access_key_id</span><span class="o">=</span><span class="s1">&#39;MY_KEY&#39;</span><span class="p">,</span> <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="s1">&#39;MY_SECRET&#39;</span><span class="p">)</span>

<span class="c1"># Put an arbitrary file in an S3 bucket</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;winning_formula.csv&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
  <span class="n">s3</span><span class="o">.</span><span class="n">put_file</span><span class="p">(</span><span class="s1">&#39;my_bucket&#39;</span><span class="p">,</span> <span class="s1">&#39;winning.csv, w)</span>

<span class="c1"># Put a Parsons Table as a CSV using convenience method.</span>
<span class="n">tbl</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="s1">&#39;winning_formula.csv&#39;</span><span class="p">)</span>
<span class="n">tbl</span><span class="o">.</span><span class="n">to_s3_csv</span><span class="p">(</span><span class="s1">&#39;my_bucket&#39;</span><span class="p">,</span> <span class="s1">&#39;winning.csv&#39;</span><span class="p">)</span>

<span class="c1"># Download a csv file and convert to a table</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">s3</span><span class="o">.</span><span class="n">get_file</span><span class="p">(</span><span class="s1">&#39;my_bucket&#39;</span><span class="p">,</span> <span class="s1">&#39;my_dir/my_file.csv&#39;</span><span class="p">)</span>
<span class="n">tbl</span> <span class="o">=</span> <span class="n">Table</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># List buckets that you have access to</span>
<span class="n">s3</span><span class="o">.</span><span class="n">list_buckets</span><span class="p">()</span>

<span class="c1"># List the keys in a bucket</span>
<span class="n">s3</span><span class="o">.</span><span class="n">list_keys</span><span class="p">(</span><span class="s1">&#39;my_bucket&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="id3">
<h3>API<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="parsons.S3">
<em class="property">class </em><code class="descclassname">parsons.</code><code class="descname">S3</code><span class="sig-paren">(</span><em>aws_access_key_id=None</em>, <em>aws_secret_access_key=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiate the S3 class.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>aws_access_key_id: str</dt>
<dd>The AWS access key id. Not required if the <code class="docutils literal notranslate"><span class="pre">AWS_ACCESS_KEY_ID</span></code> env variable
is set.</dd>
<dt>aws_secret_access_key: str</dt>
<dd>The AWS secret access key. Not required if the <code class="docutils literal notranslate"><span class="pre">AWS_SECRET_ACCESS_KEY</span></code> env
variable is set.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd>S3 class.</dd>
</dl>
<dl class="attribute">
<dt id="parsons.S3.s3">
<code class="descname">s3</code><em class="property"> = None</em><a class="headerlink" href="#parsons.S3.s3" title="Permalink to this definition">¶</a></dt>
<dd><p>Boto3 API Session Resource object. Use for more advanced boto3 features.</p>
</dd></dl>

<dl class="attribute">
<dt id="parsons.S3.client">
<code class="descname">client</code><em class="property"> = None</em><a class="headerlink" href="#parsons.S3.client" title="Permalink to this definition">¶</a></dt>
<dd><p>Boto3 API Session client object. Use for more advanced boto3 features.</p>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.list_buckets">
<code class="descname">list_buckets</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.list_buckets"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.list_buckets" title="Permalink to this definition">¶</a></dt>
<dd><p>List all buckets to which you have access.</p>
<dl class="docutils">
<dt><cite>Returns:</cite></dt>
<dd>list</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.bucket_exists">
<code class="descname">bucket_exists</code><span class="sig-paren">(</span><em>bucket</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.bucket_exists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.bucket_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine if a bucket exists and you have access to it.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The bucket name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>boolean</dt>
<dd><code class="docutils literal notranslate"><span class="pre">True</span></code> if the bucket exists and <code class="docutils literal notranslate"><span class="pre">False</span></code> if not.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.list_keys">
<code class="descname">list_keys</code><span class="sig-paren">(</span><em>bucket</em>, <em>prefix=None</em>, <em>suffix=None</em>, <em>regex=None</em>, <em>date_modified_before=None</em>, <em>date_modified_after=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.list_keys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.list_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>List the keys in a bucket, along with extra info about each one.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The bucket name</dd>
<dt>prefix: str</dt>
<dd>Limits the response to keys that begin with the specified prefix.</dd>
<dt>suffix: str</dt>
<dd>Limits the response to keys that end with specified suffix</dd>
<dt>regex: str</dt>
<dd>Limits the reponse to keys that match a regex pattern</dd>
<dt>date_modified_before: datetime.datetime</dt>
<dd>Limits the response to keys with date modified before</dd>
<dt>date_modified_after: datetime.datetime</dt>
<dd>Limits the response to keys with date modified after</dd>
<dt>kwargs:</dt>
<dd>Additional arguments for the S3 API call. See <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.list_objects_v2">AWS ListObjectsV2 documentation</a>
for more info.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>dict</dt>
<dd>Dict mapping the keys to info about each key. The info includes ‘LastModified’,
‘Size’, and ‘Owner’.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.key_exists">
<code class="descname">key_exists</code><span class="sig-paren">(</span><em>bucket</em>, <em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.key_exists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.key_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>Determine if a key exists in a bucket.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The bucket name</dd>
<dt>key: str</dt>
<dd>The object key</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>boolean</dt>
<dd><code class="docutils literal notranslate"><span class="pre">True</span></code> if key exists and <code class="docutils literal notranslate"><span class="pre">False</span></code> if not.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.create_bucket">
<code class="descname">create_bucket</code><span class="sig-paren">(</span><em>bucket</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.create_bucket"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.create_bucket" title="Permalink to this definition">¶</a></dt>
<dd><p>Create an s3 bucket.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">S3 has a limit on the number of buckets you can create in an AWS account, and
that limit is fairly low (typically 100). If you are creating buckets frequently,
you may be mis-using S3, and should consider using the same bucket for multiple tasks.
There is no limit on the number of objects in a bucket.
See <a class="reference external" href="https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html">AWS bucket restrictions</a> for more
info.</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">S3 bucket names are <em>globally</em> unique. So when creating a new bucket,
the name can’t collide with any existing bucket names. If the provided name does
collide, you’ll see errors like <cite>IllegalLocationConstraintException</cite> or
<cite>BucketAlreadyExists</cite>.</p>
</div>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The name of the bucket to create</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><code class="docutils literal notranslate"><span class="pre">None</span></code></dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.put_file">
<code class="descname">put_file</code><span class="sig-paren">(</span><em>bucket</em>, <em>key</em>, <em>local_path</em>, <em>acl='bucket-owner-full-control'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.put_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.put_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Uploads an object to an S3 bucket</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The bucket name</dd>
<dt>key: str</dt>
<dd>The object key</dd>
<dt>local_path: str</dt>
<dd>The local path of the file to upload</dd>
<dt>acl: str</dt>
<dd>The S3 permissions on the file</dd>
<dt>kwargs:</dt>
<dd>Additional arguments for the S3 API call. See <a class="reference external" href="https://docs.aws.amazon.com/AmazonS3/latest/API/RESTObjectPUT.html">AWS Put Object documentation</a> for more
info.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.remove_file">
<code class="descname">remove_file</code><span class="sig-paren">(</span><em>bucket</em>, <em>key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.remove_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.remove_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Deletes an object from an S3 bucket</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The bucket name</dd>
<dt>key: str</dt>
<dd>The object key</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><code class="docutils literal notranslate"><span class="pre">None</span></code></dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.get_file">
<code class="descname">get_file</code><span class="sig-paren">(</span><em>bucket</em>, <em>key</em>, <em>local_path=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.get_file"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.get_file" title="Permalink to this definition">¶</a></dt>
<dd><p>Download an object from S3 to a local file</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>local_path: str</dt>
<dd>The local path where the file will be downloaded. If not specified, a temporary
file will be created and returned, and that file will be removed automatically
when the script is done running.</dd>
<dt>bucket: str</dt>
<dd>The bucket name</dd>
<dt>key: str</dt>
<dd>The object key</dd>
<dt>kwargs:</dt>
<dd>Additional arguments for the S3 API call. See <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.download_file">AWS download_file documentation</a>
for more info.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>str</dt>
<dd>The path of the new file</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.get_url">
<code class="descname">get_url</code><span class="sig-paren">(</span><em>bucket</em>, <em>key</em>, <em>expires_in=3600</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.get_url"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.get_url" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a presigned url for an s3 object.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>bucket: str</dt>
<dd>The bucket name</dd>
<dt>key: str</dt>
<dd>The object name</dd>
<dt>expires_in: int</dt>
<dd>The time, in seconds, until the url expires</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Url:</dt>
<dd>A link to download the object</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.S3.transfer_bucket">
<code class="descname">transfer_bucket</code><span class="sig-paren">(</span><em>origin_bucket</em>, <em>origin_key</em>, <em>destination_bucket</em>, <em>destination_key=None</em>, <em>suffix=None</em>, <em>regex=None</em>, <em>date_modified_before=None</em>, <em>date_modified_after=None</em>, <em>public_read=False</em>, <em>remove_original=False</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/aws/s3.html#S3.transfer_bucket"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.S3.transfer_bucket" title="Permalink to this definition">¶</a></dt>
<dd><p>Transfer files between s3 buckets
<cite>Args:</cite></p>
<blockquote>
<div><dl class="docutils">
<dt>origin_bucket: str</dt>
<dd>The origin bucket</dd>
<dt>origin_key: str</dt>
<dd>The origin file or prefix</dd>
<dt>destination_bucket: str</dt>
<dd>The destination bucket</dd>
<dt>destination_key: str</dt>
<dd>If <cite>None</cite> then will retain the <cite>origin key</cite>. If set to prefix will move all
to new prefix</dd>
<dt>suffix: str</dt>
<dd>Limits the response to keys that end with specified suffix</dd>
<dt>regex: str</dt>
<dd>Limits the reponse to keys that match a regex pattern</dd>
<dt>date_modified_before: datetime.datetime</dt>
<dd>Limits the response to keys with date modified before</dd>
<dt>date_modified_after: datetime.datetime</dt>
<dd>Limits the response to keys with date modified after</dd>
<dt>public_read: bool</dt>
<dd>If the keys should be set to <cite>public-read</cite></dd>
<dt>remove_original: bool</dt>
<dd>If the original keys should be removed after transfer</dd>
<dt>kwargs:</dt>
<dd>Additional arguments for the S3 API call. See <a class="reference external" href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.copy">AWS download_file documentation</a>
for more info.</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt><cite>Returns:</cite></dt>
<dd><code class="docutils literal notranslate"><span class="pre">None</span></code></dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<p>   :members:</p>
</div>
<div class="section" id="redshift">
<h2>Redshift<a class="headerlink" href="#redshift" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id5">
<span id="id6"></span><h3>Overview<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>The Redshift class allows you to interact with an <a class="reference external" href="https://aws.amazon.com/redshift/">Amazon Redshift</a> relational database. The Redshift Connector utilizes the <code class="docutils literal notranslate"><span class="pre">psycopg2</span></code> python package to connect to the database.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<dl class="last docutils">
<dt>S3 Credentials</dt>
<dd>Redshift only allows data to be copied to the database via S3. As such, the the <code class="xref py py-meth docutils literal notranslate"><span class="pre">copy()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">copy_s3()</span></code>
methods require S3 credentials and write access on an S3 Bucket, which will be used for storing data en route to
Redshift.</dd>
<dt>Whitelisting</dt>
<dd>Remember to ensure that the IP address from which you are connecting has been whitelisted.</dd>
</dl>
</div>
</div>
<div class="section" id="id7">
<h3>Quickstart<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p><strong>Query the Database</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">parsons</span> <span class="kn">import</span> <span class="n">Redshift</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">Redshift</span><span class="p">()</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;select * from tmc_scratch.test_data&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Copy a Parsons Table to the Database</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">parsons</span> <span class="kn">import</span> <span class="n">Redshift</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">Redshift</span><span class="p">()</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">rs</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">tbl</span><span class="p">,</span> <span class="s1">&#39;tmc_scratch.test_table&#39;</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="s1">&#39;drop&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>All of the standard copy options can be passed as kwargs. See the <code class="xref py py-meth docutils literal notranslate"><span class="pre">copy()</span></code> method for all
options.</p>
</div>
<div class="section" id="core-api">
<h3>Core API<a class="headerlink" href="#core-api" title="Permalink to this headline">¶</a></h3>
<p>Redshift core methods focus on input, output and querying of the database.</p>
<dl class="class">
<dt id="parsons.Redshift">
<em class="property">class </em><code class="descclassname">parsons.</code><code class="descname">Redshift</code><span class="sig-paren">(</span><em>username=None</em>, <em>password=None</em>, <em>host=None</em>, <em>db=None</em>, <em>port=None</em>, <em>timeout=10</em>, <em>s3_temp_bucket=None</em>, <em>aws_access_key_id=None</em>, <em>aws_secret_access_key=None</em>, <em>iam_role=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/redshift.html#Redshift"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.Redshift" title="Permalink to this definition">¶</a></dt>
<dd><p>A Redshift class to connect to database.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>username: str</dt>
<dd>Required if env variable <code class="docutils literal notranslate"><span class="pre">REDSHIFT_USERNAME</span></code> not populated</dd>
<dt>password: str</dt>
<dd>Required if env variable <code class="docutils literal notranslate"><span class="pre">REDSHIFT_PASSWORD</span></code> not populated</dd>
<dt>host: str</dt>
<dd>Required if env variable <code class="docutils literal notranslate"><span class="pre">REDSHIFT_HOST</span></code> not populated</dd>
<dt>db: str</dt>
<dd>Required if env variable <code class="docutils literal notranslate"><span class="pre">REDSHIFT_DB</span></code> not populated</dd>
<dt>port: int</dt>
<dd>Required if env variable <code class="docutils literal notranslate"><span class="pre">REDSHIFT_PORT</span></code> not populated. Port 5439 is typical.</dd>
<dt>timeout: int</dt>
<dd>Seconds to timeout if connection not established</dd>
<dt>s3_temp_bucket: str</dt>
<dd>Name of the S3 bucket that will be used for storing data during bulk transfers.
Required if you intend to perform bulk data transfers (eg. the copy_s3 method),
and env variable <code class="docutils literal notranslate"><span class="pre">S3_TEMP_BUCKET</span></code> is not populated.</dd>
<dt>aws_access_key_id: str</dt>
<dd>The default AWS access key id for copying data from S3 into Redshift
when running copy/upsert/etc methods.
This will default to environment variable AWS_ACCESS_KEY_ID.</dd>
<dt>aws_secret_access_key: str</dt>
<dd>The default AWS secret access key for copying data from S3 into Redshift
when running copy/upsert/etc methods.
This will default to environment variable AWS_SECRET_ACCESS_KEY.</dd>
<dt>iam_role: str</dt>
<dd>AWS IAM Role ARN string – an optional, different way for credentials to
be provided in the Redshift copy command that does not require an access key.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.connection">
<code class="descclassname">parsons.Redshift.</code><code class="descname">connection</code><span class="sig-paren">(</span><em>self</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.connection" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a Redshift connection.
The connection is set up as a python “context manager”, so it will be closed
automatically (and all queries committed) when the connection goes out of scope.</p>
<p>When using the connection, make sure to put it in a <code class="docutils literal notranslate"><span class="pre">with</span></code> block (necessary for
any context manager):
<code class="docutils literal notranslate"><span class="pre">with</span> <span class="pre">rs.connection()</span> <span class="pre">as</span> <span class="pre">conn:</span></code></p>
<dl class="docutils">
<dt><cite>Returns:</cite></dt>
<dd>Psycopg2 <cite>connection</cite> object</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.query">
<code class="descclassname">parsons.Redshift.</code><code class="descname">query</code><span class="sig-paren">(</span><em>self</em>, <em>sql</em>, <em>parameters=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.query" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a query against the Redshift database. Will return <code class="docutils literal notranslate"><span class="pre">None</span></code>
if the query returns zero rows.</p>
<p>To include python variables in your query, it is recommended to pass them as parameters,
following the <a class="reference external" href="http://initd.org/psycopg/docs/usage.html#passing-parameters-to-sql-queries">psycopg style</a>.
Using the <code class="docutils literal notranslate"><span class="pre">parameters</span></code> argument ensures that values are escaped properly, and avoids SQL
injection attacks.</p>
<p><strong>Parameter Examples</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note that the name contains a quote, which could break your query if not escaped</span>
<span class="c1"># properly.</span>
<span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;Beatrice O&#39;Brady&quot;</span>
<span class="n">sql</span> <span class="o">=</span> <span class="s2">&quot;SELECT * FROM my_table WHERE name = </span><span class="si">%s</span><span class="s2">&quot;</span>
<span class="n">rs</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Allen Smith&quot;</span><span class="p">,</span> <span class="s2">&quot;Beatrice O&#39;Brady&quot;</span><span class="p">,</span> <span class="s2">&quot;Cathy Thompson&quot;</span><span class="p">]</span>
<span class="n">placeholders</span> <span class="o">=</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">names</span><span class="p">)</span>
<span class="n">sql</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;SELECT * FROM my_table WHERE name IN (</span><span class="si">{</span><span class="n">placeholders</span><span class="si">}</span><span class="s2">)&quot;</span>
<span class="n">rs</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">sql</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
</pre></div>
</div>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>sql: str</dt>
<dd>A valid SQL statement</dd>
<dt>parameters: list</dt>
<dd>A list of python variables to be converted into SQL values in your query</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table</dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.query_with_connection">
<code class="descclassname">parsons.Redshift.</code><code class="descname">query_with_connection</code><span class="sig-paren">(</span><em>self</em>, <em>sql</em>, <em>connection</em>, <em>parameters=None</em>, <em>commit=True</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.query_with_connection" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a query against the Redshift database, with an existing connection.
Useful for batching queries together. Will return <code class="docutils literal notranslate"><span class="pre">None</span></code> if the query
returns zero rows.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>sql: str</dt>
<dd>A valid SQL statement</dd>
<dt>connection: obj</dt>
<dd>A connection object obtained from <code class="docutils literal notranslate"><span class="pre">redshift.connection()</span></code></dd>
<dt>parameters: list</dt>
<dd>A list of python variables to be converted into SQL values in your query</dd>
<dt>commit: boolean</dt>
<dd>Whether to commit the transaction immediately. If <code class="docutils literal notranslate"><span class="pre">False</span></code> the transaction will
be committed when the connection goes out of scope and is closed (or you can
commit manually with <code class="docutils literal notranslate"><span class="pre">connection.commit()</span></code>).</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table</dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.copy">
<code class="descclassname">parsons.Redshift.</code><code class="descname">copy</code><span class="sig-paren">(</span><em>self</em>, <em>tbl</em>, <em>table_name</em>, <em>if_exists='fail'</em>, <em>max_errors=0</em>, <em>distkey=None</em>, <em>sortkey=None</em>, <em>padding=None</em>, <em>statupdate=False</em>, <em>compupdate=True</em>, <em>acceptanydate=True</em>, <em>emptyasnull=True</em>, <em>blanksasnull=True</em>, <em>nullas=None</em>, <em>acceptinvchars=True</em>, <em>dateformat='auto'</em>, <em>timeformat='auto'</em>, <em>varchar_max=None</em>, <em>truncatecolumns=False</em>, <em>columntypes=None</em>, <em>specifycols=None</em>, <em>alter_table=False</em>, <em>aws_access_key_id=None</em>, <em>aws_secret_access_key=None</em>, <em>iam_role=None</em>, <em>cleanup_s3_file=True</em>, <em>template_table=None</em>, <em>temp_bucket_region=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy a <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> to Redshift.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>tbl: obj</dt>
<dd>A Parsons Table.</dd>
<dt>table_name: str</dt>
<dd>The destination table name (ex. <code class="docutils literal notranslate"><span class="pre">my_schema.my_table</span></code>).</dd>
<dt>if_exists: str</dt>
<dd>If the table already exists, either <code class="docutils literal notranslate"><span class="pre">fail</span></code>, <code class="docutils literal notranslate"><span class="pre">append</span></code>, <code class="docutils literal notranslate"><span class="pre">drop</span></code>
or <code class="docutils literal notranslate"><span class="pre">truncate</span></code> the table.</dd>
<dt>max_errors: int</dt>
<dd>The maximum number of rows that can error and be skipped before
the job fails.</dd>
<dt>distkey: str</dt>
<dd>The column name of the distkey</dd>
<dt>sortkey: str</dt>
<dd>The column name of the sortkey</dd>
<dt>padding: float</dt>
<dd>A percentage padding to add to varchar columns if creating a new table. This is
helpful to add a buffer for future copies in which the data might be wider.</dd>
<dt>varchar_max: list</dt>
<dd>A list of columns in which to set the width of the varchar column to 65,535
characters.</dd>
<dt>statupate: boolean</dt>
<dd>Governs automatic computation and refresh of optimizer statistics at the end
of a successful COPY command.</dd>
<dt>compupdate: boolean</dt>
<dd>Controls whether compression encodings are automatically applied during a COPY.</dd>
<dt>acceptanydate: boolean</dt>
<dd>Allows any date format, including invalid formats such as 00/00/00 00:00:00, to be
loaded without generating an error.</dd>
<dt>emptyasnull: boolean</dt>
<dd>Indicates that Amazon Redshift should load empty char and varchar fields
as <code class="docutils literal notranslate"><span class="pre">NULL</span></code>.</dd>
<dt>blanksasnull: boolean</dt>
<dd>Loads blank varchar fields, which consist of only white space characters,
as <code class="docutils literal notranslate"><span class="pre">NULL</span></code>.</dd>
<dt>nullas: str</dt>
<dd>Loads fields that match string as NULL</dd>
<dt>acceptinvchars: boolean</dt>
<dd>Enables loading of data into VARCHAR columns even if the data contains
invalid UTF-8 characters.</dd>
<dt>dateformat: str</dt>
<dd>Set the date format. Defaults to <code class="docutils literal notranslate"><span class="pre">auto</span></code>.</dd>
<dt>timeformat: str</dt>
<dd>Set the time format. Defaults to <code class="docutils literal notranslate"><span class="pre">auto</span></code>.</dd>
<dt>truncatecolumns: boolean</dt>
<dd>If the table already exists, truncates data in columns to the appropriate number
of characters so that it fits the column specification. Applies only to columns
with a VARCHAR or CHAR data type, and rows 4 MB or less in size.</dd>
<dt>columntypes: dict</dt>
<dd>Optional map of column name to redshift column type, overriding the usual type
inference. You only specify the columns you want to override, eg.
<code class="docutils literal notranslate"><span class="pre">columntypes={'phone':</span> <span class="pre">'varchar(12)',</span> <span class="pre">'age':</span> <span class="pre">'int'})</span></code>.</dd>
<dt>specifycols: boolean</dt>
<dd><p class="first">Adds a column list to the Redshift <cite>COPY</cite> command, allowing for the source table
in an append to have the columnns out of order, and to have fewer columns with any
leftover target table columns filled in with the <cite>DEFAULT</cite> value.</p>
<p class="last">This will fail if all of the source table’s columns do not match a column in the
target table. This will also fail if the target table has an <cite>IDENTITY</cite>
column and that column name is among the source table’s columns.</p>
</dd>
<dt>alter_table: boolean</dt>
<dd>Will check if the target table varchar widths are wide enough to copy in the
table data. If not, will attempt to alter the table to make it wide enough. This
will not work with tables that have dependent views.</dd>
<dt>aws_access_key_id:</dt>
<dd>An AWS access key granted to the bucket where the file is located. Not required
if keys are stored as environmental variables.</dd>
<dt>aws_secret_access_key:</dt>
<dd>An AWS secret access key granted to the bucket where the file is located. Not
required if keys are stored as environmental variables.</dd>
<dt>iam_role: str</dt>
<dd>An AWS IAM Role ARN string; an alternative credential for the COPY command
from Redshift to S3. The IAM role must have been assigned to the Redshift
instance and have access to the S3 bucket.</dd>
<dt>cleanup_s3_file: boolean</dt>
<dd>The s3 upload is removed by default on cleanup. You can set to False for debugging.</dd>
<dt>template_table: str</dt>
<dd>Instead of specifying columns, columntypes, and/or inference, if there
is a pre-existing table that has the same columns/types, then use the template_table
table name as the schema for the new table.
Unless you set specifycols=False explicitly, a template_table will set it to True</dd>
<dt>temp_bucket_region: str</dt>
<dd>The AWS region that the temp bucket (specified by the TEMP_S3_BUCKET environment
variable) is located in. This should be provided if the Redshift cluster is located
in a different region from the temp bucket.</dd>
</dl>
</dd>
<dt><cite>Returns</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table or <code class="docutils literal notranslate"><span class="pre">None</span></code></dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.copy_s3">
<code class="descclassname">parsons.Redshift.</code><code class="descname">copy_s3</code><span class="sig-paren">(</span><em>self</em>, <em>table_name</em>, <em>bucket</em>, <em>key</em>, <em>manifest=False</em>, <em>data_type='csv'</em>, <em>csv_delimiter='</em>, <em>'</em>, <em>compression=None</em>, <em>if_exists='fail'</em>, <em>max_errors=0</em>, <em>distkey=None</em>, <em>sortkey=None</em>, <em>padding=None</em>, <em>varchar_max=None</em>, <em>statupdate=True</em>, <em>compupdate=True</em>, <em>ignoreheader=1</em>, <em>acceptanydate=True</em>, <em>dateformat='auto'</em>, <em>timeformat='auto'</em>, <em>emptyasnull=True</em>, <em>blanksasnull=True</em>, <em>nullas=None</em>, <em>acceptinvchars=True</em>, <em>truncatecolumns=False</em>, <em>columntypes=None</em>, <em>specifycols=None</em>, <em>aws_access_key_id=None</em>, <em>aws_secret_access_key=None</em>, <em>bucket_region=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.copy_s3" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy a file from s3 to Redshift.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table_name: str</dt>
<dd>The table name and schema (<code class="docutils literal notranslate"><span class="pre">tmc.cool_table</span></code>) to point the file.</dd>
<dt>bucket: str</dt>
<dd>The s3 bucket where the file or manifest is located.</dd>
<dt>key: str</dt>
<dd>The key of the file or manifest in the s3 bucket.</dd>
<dt>manifest: str</dt>
<dd>If using a manifest</dd>
<dt>data_type: str</dt>
<dd>The data type of the file. Only <code class="docutils literal notranslate"><span class="pre">csv</span></code> supported currently.</dd>
<dt>csv_delimiter: str</dt>
<dd>The delimiter of the <code class="docutils literal notranslate"><span class="pre">csv</span></code>. Only relevant if data_type is <code class="docutils literal notranslate"><span class="pre">csv</span></code>.</dd>
<dt>compression: str</dt>
<dd>If specified (<code class="docutils literal notranslate"><span class="pre">gzip</span></code>), will attempt to decompress the file.</dd>
<dt>if_exists: str</dt>
<dd>If the table already exists, either <code class="docutils literal notranslate"><span class="pre">fail</span></code>, <code class="docutils literal notranslate"><span class="pre">append</span></code>, <code class="docutils literal notranslate"><span class="pre">drop</span></code>
or <code class="docutils literal notranslate"><span class="pre">truncate</span></code> the table.</dd>
<dt>max_errors: int</dt>
<dd>The maximum number of rows that can error and be skipped before
the job fails.</dd>
<dt>distkey: str</dt>
<dd>The column name of the distkey</dd>
<dt>sortkey: str</dt>
<dd>The column name of the sortkey</dd>
<dt>padding: float</dt>
<dd>A percentage padding to add to varchar columns if creating a new table. This is
helpful to add a buffer for future copies in which the data might be wider.</dd>
<dt>varchar_max: list</dt>
<dd>A list of columns in which to set the width of the varchar column to 65,535
characters.</dd>
<dt>statupate: boolean</dt>
<dd>Governs automatic computation and refresh of optimizer statistics at the end
of a successful COPY command.</dd>
<dt>compupdate: boolean</dt>
<dd>Controls whether compression encodings are automatically applied during a COPY.</dd>
<dt>ignore_header: int</dt>
<dd>The number of header rows to skip. Ignored if data_type is <code class="docutils literal notranslate"><span class="pre">json</span></code>.</dd>
<dt>acceptanydate: boolean</dt>
<dd>Allows any date format, including invalid formats such as 00/00/00 00:00:00, to be
loaded without generating an error.</dd>
<dt>emptyasnull: boolean</dt>
<dd>Indicates that Amazon Redshift should load empty char and varchar fields
as <code class="docutils literal notranslate"><span class="pre">NULL</span></code>.</dd>
<dt>blanksasnull: boolean</dt>
<dd>Loads blank varchar fields, which consist of only white space characters,
as <code class="docutils literal notranslate"><span class="pre">NULL</span></code>.</dd>
<dt>nullas: str</dt>
<dd>Loads fields that match string as NULL</dd>
<dt>acceptinvchars: boolean</dt>
<dd>Enables loading of data into VARCHAR columns even if the data contains
invalid UTF-8 characters.</dd>
<dt>dateformat: str</dt>
<dd>Set the date format. Defaults to <code class="docutils literal notranslate"><span class="pre">auto</span></code>.</dd>
<dt>timeformat: str</dt>
<dd>Set the time format. Defaults to <code class="docutils literal notranslate"><span class="pre">auto</span></code>.</dd>
<dt>truncatecolumns: boolean</dt>
<dd>If the table already exists, truncates data in columns to the appropriate number
of characters so that it fits the column specification. Applies only to columns
with a VARCHAR or CHAR data type, and rows 4 MB or less in size.</dd>
<dt>columntypes: dict</dt>
<dd>Optional map of column name to redshift column type, overriding the usual type
inference. You only specify the columns you want to override, eg.
<code class="docutils literal notranslate"><span class="pre">columntypes={'phone':</span> <span class="pre">'varchar(12)',</span> <span class="pre">'age':</span> <span class="pre">'int'})</span></code>.</dd>
<dt>specifycols: boolean</dt>
<dd><p class="first">Adds a column list to the Redshift <cite>COPY</cite> command, allowing for the source table
in an append to have the columnns out of order, and to have fewer columns with any
leftover target table columns filled in with the <cite>DEFAULT</cite> value.</p>
<p class="last">This will fail if all of the source table’s columns do not match a column in the
target table. This will also fail if the target table has an <cite>IDENTITY</cite>
column and that column name is among the source table’s columns.</p>
</dd>
<dt>aws_access_key_id:</dt>
<dd>An AWS access key granted to the bucket where the file is located. Not required
if keys are stored as environmental variables.</dd>
<dt>aws_secret_access_key:</dt>
<dd>An AWS secret access key granted to the bucket where the file is located. Not
required if keys are stored as environmental variables.</dd>
<dt>bucket_region: str</dt>
<dd>The AWS region that the bucket is located in. This should be provided if the
Redshift cluster is located in a different region from the temp bucket.</dd>
</dl>
</dd>
<dt><cite>Returns</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table or <code class="docutils literal notranslate"><span class="pre">None</span></code></dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.unload">
<code class="descclassname">parsons.Redshift.</code><code class="descname">unload</code><span class="sig-paren">(</span><em>self</em>, <em>sql</em>, <em>bucket</em>, <em>key_prefix</em>, <em>manifest=True</em>, <em>header=True</em>, <em>delimiter='|'</em>, <em>compression='gzip'</em>, <em>add_quotes=True</em>, <em>null_as=None</em>, <em>escape=True</em>, <em>allow_overwrite=True</em>, <em>parallel=True</em>, <em>max_file_size='6.2 GB'</em>, <em>aws_region=None</em>, <em>aws_access_key_id=None</em>, <em>aws_secret_access_key=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.unload" title="Permalink to this definition">¶</a></dt>
<dd><p>Unload Redshift data to S3 Bucket. This is a more efficient method than running a query
to export data as it can export in parallel and directly into an S3 bucket. Consider
using this for exports of 10MM or more rows.</p>
<dl class="docutils">
<dt>sql: str</dt>
<dd>The SQL string to execute to generate the data to unload.</dd>
<dt>buckey: str</dt>
<dd>The destination S3 bucket</dd>
<dt>key_prefix: str</dt>
<dd>The prefix of the key names that will be written</dd>
<dt>manifest: boolean</dt>
<dd>Creates a manifest file that explicitly lists details for the data files
that are created by the UNLOAD process.</dd>
<dt>header: boolean</dt>
<dd>Adds a header line containing column names at the top of each output file.</dd>
<dt>delimiter: str</dt>
<dd>Specificies the character used to separate fields. Defaults to ‘|’.</dd>
<dt>compression: str</dt>
<dd>One of <code class="docutils literal notranslate"><span class="pre">gzip</span></code>, <code class="docutils literal notranslate"><span class="pre">bzip2</span></code> or <code class="docutils literal notranslate"><span class="pre">None</span></code>. Unloads data to one or more compressed
files per slice. Each resulting file is appended with a <code class="docutils literal notranslate"><span class="pre">.gz</span></code> or <code class="docutils literal notranslate"><span class="pre">.bz2</span></code> extension.</dd>
<dt>add_quotes: boolean</dt>
<dd>Places quotation marks around each unloaded data field, so that Amazon Redshift
can unload data values that contain the delimiter itself.</dd>
<dt>null_as: str</dt>
<dd>Specifies a string that represents a null value in unload files. If this option is
not specified, null values are unloaded as zero-length strings for delimited output.</dd>
<dt>escape: boolean</dt>
<dd>For CHAR and VARCHAR columns in delimited unload files, an escape character () is
placed before every linefeed, carriage return, escape characters and delimiters.</dd>
<dt>allow_overwrite: boolean</dt>
<dd>If <code class="docutils literal notranslate"><span class="pre">True</span></code>, will overwrite existing files, including the manifest file. If <code class="docutils literal notranslate"><span class="pre">False</span></code>
will fail.</dd>
<dt>parallel: boolean</dt>
<dd>By default, UNLOAD writes data in parallel to multiple files, according to the number
of slices in the cluster. The default option is ON or TRUE. If PARALLEL is OFF or
FALSE, UNLOAD writes to one or more data files serially, sorted absolutely according
to the ORDER BY clause, if one is used.</dd>
<dt>max_file_size: str</dt>
<dd>The maximum size of files UNLOAD creates in Amazon S3. Specify a decimal value between
5 MB and 6.2 GB.</dd>
<dt>region: str</dt>
<dd>The AWS Region where the target Amazon S3 bucket is located. REGION is required for
UNLOAD to an Amazon S3 bucket that is not in the same AWS Region as the Amazon Redshift
cluster.</dd>
<dt>aws_access_key_id:</dt>
<dd>An AWS access key granted to the bucket where the file is located. Not required
if keys are stored as environmental variables.</dd>
<dt>aws_secret_access_key:</dt>
<dd>An AWS secret access key granted to the bucket where the file is located. Not
required if keys are stored as environmental variables.</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.upsert">
<code class="descclassname">parsons.Redshift.</code><code class="descname">upsert</code><span class="sig-paren">(</span><em>self</em>, <em>table_obj</em>, <em>target_table</em>, <em>primary_key</em>, <em>vacuum=True</em>, <em>distinct_check=True</em>, <em>cleanup_temp_table=True</em>, <em>alter_table=True</em>, <em>**copy_args</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.upsert" title="Permalink to this definition">¶</a></dt>
<dd><p>Preform an upsert on an existing table. An upsert is a function in which records
in a table are updated and inserted at the same time. Unlike other SQL databases,
it does not exist natively in Redshift.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table_obj: obj</dt>
<dd>A Parsons table object</dd>
<dt>target_table: str</dt>
<dd>The schema and table name to upsert</dd>
<dt>primary_key: str or list</dt>
<dd>The primary key column(s) of the target table</dd>
<dt>vacuum: boolean</dt>
<dd>Re-sorts rows and reclaims space in the specified table. You must be a table owner
or super user to effectively vacuum a table, however the method will not fail
if you lack these priviledges.</dd>
<dt>distinct_check: boolean</dt>
<dd>Check if the primary key column is distinct. Raise error if not.</dd>
<dt>cleanup_temp_table: boolean</dt>
<dd>A temp table is dropped by default on cleanup. You can set to False for debugging.</dd>
<dt>**copy_args: kwargs</dt>
<dd>See <code class="xref py py-func docutils literal notranslate"><span class="pre">copy`()</span></code> for options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.generate_manifest">
<code class="descclassname">parsons.Redshift.</code><code class="descname">generate_manifest</code><span class="sig-paren">(</span><em>self</em>, <em>buckets</em>, <em>aws_access_key_id=None</em>, <em>aws_secret_access_key=None</em>, <em>mandatory=True</em>, <em>prefix=None</em>, <em>manifest_bucket=None</em>, <em>manifest_key=None</em>, <em>path=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.generate_manifest" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a list of S3 buckets, generate a manifest file (JSON format). A manifest file
allows you to copy multiple files into a single table at once. Once the manifest is
generated, you can pass it with the <code class="xref py py-func docutils literal notranslate"><span class="pre">copy_s3()</span></code> method.</p>
<p>AWS keys are not required if <code class="docutils literal notranslate"><span class="pre">AWS_ACCESS_KEY_ID</span></code> and
<code class="docutils literal notranslate"><span class="pre">AWS_SECRET_ACCESS_KEY</span></code> environmental variables set.</p>
<p><cite>Args:</cite></p>
<blockquote>
<div><dl class="docutils">
<dt>buckets: list or str</dt>
<dd>A list of buckets or single bucket from which to generate manifest</dd>
<dt>aws_access_key_id: str</dt>
<dd>AWS access key id to access S3 bucket</dd>
<dt>aws_secret_access_key: str</dt>
<dd>AWS secret access key to access S3 bucket</dd>
<dt>mandatory: boolean</dt>
<dd>The mandatory flag indicates whether the Redshift COPY should
terminate if the file does not exist.</dd>
<dt>prefix: str</dt>
<dd>Optional filter for key prefixes</dd>
<dt>manifest_bucket: str</dt>
<dd>Optional bucket to write manifest file.</dd>
<dt>manifest_key: str</dt>
<dd>Optional key name for S3 bucket to write file</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt><cite>Returns:</cite></dt>
<dd><code class="docutils literal notranslate"><span class="pre">dict</span></code> of manifest</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="parsons.Redshift.alter_table_column_type">
<code class="descclassname">parsons.Redshift.</code><code class="descname">alter_table_column_type</code><span class="sig-paren">(</span><em>self</em>, <em>table_name</em>, <em>column_name</em>, <em>data_type</em>, <em>varchar_width=None</em><span class="sig-paren">)</span><a class="headerlink" href="#parsons.Redshift.alter_table_column_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Alter a column type of an existing table.</p>
<dl class="docutils">
<dt>table_name: str</dt>
<dd>The table name (ex. <code class="docutils literal notranslate"><span class="pre">my_schema.my_table</span></code>).</dd>
<dt>column_name: str</dt>
<dd>The target column name</dd>
<dt>data_type: str</dt>
<dd>A valid Redshift data type to alter the table to.</dd>
<dt>varchar_width:</dt>
<dd>The new width of the column if of type varchar.</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="table-and-view-api">
<h3>Table and View API<a class="headerlink" href="#table-and-view-api" title="Permalink to this headline">¶</a></h3>
<p>Table and view utilities are a series of helper methods, all built off of commonly
used SQL queries run against the Redshift database.</p>
<dl class="class">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities">
<em class="property">class </em><code class="descclassname">parsons.databases.redshift.redshift.</code><code class="descname">RedshiftTableUtilities</code><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.table_exists">
<code class="descname">table_exists</code><span class="sig-paren">(</span><em>table_name</em>, <em>view=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.table_exists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.table_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if a table or view exists in the database.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table_name: str</dt>
<dd>The table name and schema (e.g. <code class="docutils literal notranslate"><span class="pre">myschema.mytable</span></code>).</dd>
<dt>view: boolean</dt>
<dd>Check to see if a view exists by the same name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>boolean</dt>
<dd><code class="docutils literal notranslate"><span class="pre">True</span></code> if the table exists and <code class="docutils literal notranslate"><span class="pre">False</span></code> if it does not.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_row_count">
<code class="descname">get_row_count</code><span class="sig-paren">(</span><em>table_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_row_count"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_row_count" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the row count of a table.</p>
<p><strong>SQL Code</strong></p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">FROM</span> <span class="n">myschema</span><span class="p">.</span><span class="n">mytable</span>
</pre></div>
</div>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table_name: str</dt>
<dd>The schema and name (e.g. <code class="docutils literal notranslate"><span class="pre">myschema.mytable</span></code>) of the table.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd>int</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.rename_table">
<code class="descname">rename_table</code><span class="sig-paren">(</span><em>table_name</em>, <em>new_table_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.rename_table"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.rename_table" title="Permalink to this definition">¶</a></dt>
<dd><p>Rename an existing table.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You cannot move schemas when renaming a table. Instead, utilize
the <code class="xref py py-meth docutils literal notranslate"><span class="pre">table_duplicate()</span></code>. method.</p>
</div>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>table_name: str</dt>
<dd>Name of existing schema and table (e.g. <code class="docutils literal notranslate"><span class="pre">myschema.oldtable</span></code>)</dd>
<dt>new_table_name: str</dt>
<dd>New name for table with the schema omitted (e.g. <code class="docutils literal notranslate"><span class="pre">newtable</span></code>).</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.move_table">
<code class="descname">move_table</code><span class="sig-paren">(</span><em>source_table</em>, <em>new_table</em>, <em>drop_source_table=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.move_table"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.move_table" title="Permalink to this definition">¶</a></dt>
<dd><p>Move an existing table in the database.It will inherit encoding, sortkey
and distkey. <strong>Once run, the source table rows will be empty.</strong> This is
more efficiant than running <code class="docutils literal notranslate"><span class="pre">&quot;create</span> <span class="pre">newtable</span> <span class="pre">as</span> <span class="pre">select</span> <span class="pre">*</span> <span class="pre">from</span> <span class="pre">oldtable&quot;</span></code>.</p>
<p>For more information see: <a class="reference external" href="https://docs.aws.amazon.com/redshift/latest/dg/r_ALTER_TABLE_APPEND.html">ALTER TABLE APPEND</a></p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>source_table: str</dt>
<dd>Name of existing schema and table (e.g. <code class="docutils literal notranslate"><span class="pre">my_schema.old_table</span></code>)</dd>
<dt>new_table: str</dt>
<dd>New name of schema and table (e.g. <code class="docutils literal notranslate"><span class="pre">my_schema.newtable</span></code>)</dd>
<dt>drop_original: boolean</dt>
<dd>Drop the source table.</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>None</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.populate_table_from_query">
<code class="descname">populate_table_from_query</code><span class="sig-paren">(</span><em>query</em>, <em>destination_table</em>, <em>if_exists='fail'</em>, <em>distkey=None</em>, <em>sortkey=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.populate_table_from_query"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.populate_table_from_query" title="Permalink to this definition">¶</a></dt>
<dd><p>Populate a Redshift table with the results of a SQL query, creating the table if it
doesn’t yet exist.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>query: str</dt>
<dd>The SQL query</dd>
<dt>destination_table: str</dt>
<dd>Name of destination schema and table (e.g. <code class="docutils literal notranslate"><span class="pre">mys_chema.new_table</span></code>)</dd>
<dt>if_exists: str</dt>
<dd>If the table already exists, either <code class="docutils literal notranslate"><span class="pre">fail</span></code>, <code class="docutils literal notranslate"><span class="pre">append</span></code>, <code class="docutils literal notranslate"><span class="pre">drop</span></code>,
or <code class="docutils literal notranslate"><span class="pre">truncate</span></code> the table.</dd>
<dt>distkey: str</dt>
<dd>The column to use as the distkey for the table.</dd>
<dt>sortkey: str</dt>
<dd>The column to use as the sortkey for the table.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.duplicate_table">
<code class="descname">duplicate_table</code><span class="sig-paren">(</span><em>source_table</em>, <em>destination_table</em>, <em>where_clause=''</em>, <em>if_exists='fail'</em>, <em>drop_source_table=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.duplicate_table"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.duplicate_table" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a copy of an existing table (or subset of rows) in a new
table. It will inherit encoding, sortkey and distkey.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>source_table: str</dt>
<dd>Name of existing schema and table (e.g. <code class="docutils literal notranslate"><span class="pre">myschema.oldtable</span></code>)</dd>
<dt>destination_table: str</dt>
<dd>Name of destination schema and table (e.g. <code class="docutils literal notranslate"><span class="pre">myschema.newtable</span></code>)</dd>
<dt>where_clause: str</dt>
<dd>An optional where clause (e.g. <code class="docutils literal notranslate"><span class="pre">where</span> <span class="pre">org</span> <span class="pre">=</span> <span class="pre">1</span></code>).</dd>
<dt>if_exists: str</dt>
<dd>If the table already exists, either <code class="docutils literal notranslate"><span class="pre">fail</span></code>, <code class="docutils literal notranslate"><span class="pre">append</span></code>, <code class="docutils literal notranslate"><span class="pre">drop</span></code>,
or <code class="docutils literal notranslate"><span class="pre">truncate</span></code> the table.</dd>
<dt>drop_source_table: boolean</dt>
<dd>Drop the source table</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.union_tables">
<code class="descname">union_tables</code><span class="sig-paren">(</span><em>new_table_name</em>, <em>tables</em>, <em>union_all=True</em>, <em>view=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.union_tables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.union_tables" title="Permalink to this definition">¶</a></dt>
<dd><p>Union a series of table into a new table.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>new_table_name: str</dt>
<dd>The new table and schema (e.g. <code class="docutils literal notranslate"><span class="pre">myschema.newtable</span></code>)</dd>
<dt>tables: list</dt>
<dd>A list of tables to union</dd>
<dt>union_all: boolean</dt>
<dd>If <code class="docutils literal notranslate"><span class="pre">False</span></code> will deduplicate rows. If <code class="docutils literal notranslate"><span class="pre">True</span></code> will include
duplicate rows.</dd>
<dt>view: boolean</dt>
<dd>Create a view rather than a static table</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>None</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_tables">
<code class="descname">get_tables</code><span class="sig-paren">(</span><em>schema=None</em>, <em>table_name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_tables"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_tables" title="Permalink to this definition">¶</a></dt>
<dd><p>List the tables in a schema including metadata.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>Filter by a schema</dd>
<dt>table_name: str</dt>
<dd>Filter by a table name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table</dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_table_stats">
<code class="descname">get_table_stats</code><span class="sig-paren">(</span><em>schema=None</em>, <em>table_name=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_table_stats"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_table_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>List the tables statistics includes row count and size.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This method is only accessible by Redshift <em>superusers</em>.</p>
</div>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>Filter by a schema</dd>
<dt>table_name: str</dt>
<dd>Filter by a table name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table</dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_columns">
<code class="descname">get_columns</code><span class="sig-paren">(</span><em>schema</em>, <em>table_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_columns"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_columns" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the column names (and some other column info) for a table.</p>
<p>If you just need the column names, run <code class="docutils literal notranslate"><span class="pre">get_columns_list()</span></code> as it is faster.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">rs</span><span class="o">.</span><span class="n">get_columns</span><span class="p">(</span><span class="s1">&#39;some_schema&#39;</span><span class="p">,</span> <span class="s1">&#39;some_table&#39;</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
</pre></div>
</div>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema name</dd>
<dt>table_name: str</dt>
<dd>The table name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><p class="first">A dict mapping column name to a dict with extra info. The keys of the dict are ordered
just like the columns in the table. The extra info is a dict with format
<a href="#id8"><span class="problematic" id="id9">``</span></a>{‘data_type’: str, ‘max_length’: int or None, ‘max_precision’: int or None,</p>
<blockquote class="last">
<div>‘max_scale’: int or None, ‘is_nullable’: bool}``</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_columns_list">
<code class="descname">get_columns_list</code><span class="sig-paren">(</span><em>schema</em>, <em>table_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_columns_list"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_columns_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the just the column names for a table.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema name</dd>
<dt>table_name: str</dt>
<dd>The table name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd>A list of column names.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_views">
<code class="descname">get_views</code><span class="sig-paren">(</span><em>schema=None</em>, <em>view=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_views"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_views" title="Permalink to this definition">¶</a></dt>
<dd><p>List views.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>Filter by a schema</dd>
<dt>view: str</dt>
<dd>Filter by a table name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table</dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_queries">
<code class="descname">get_queries</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_queries"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_queries" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Current queries running and queueing, along with resource consumption.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Must be a Redshift superuser to run this method.</p>
</div>
<dl class="docutils">
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>Parsons Table</dt>
<dd>See <a class="reference internal" href="table.html#parsons-table"><span class="std std-ref">Parsons Table</span></a> for output options.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_max_value">
<code class="descname">get_max_value</code><span class="sig-paren">(</span><em>table_name</em>, <em>value_column</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_max_value"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_max_value" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the max value from a table.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table_name: str</dt>
<dd>Schema and table name</dd>
<dt>value_column: str</dt>
<dd>The column containing the values</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_object_type">
<code class="descname">get_object_type</code><span class="sig-paren">(</span><em>object_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_object_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_object_type" title="Permalink to this definition">¶</a></dt>
<dd><p>Get object type.</p>
<p>One of <cite>view</cite>, <cite>table</cite>, <cite>index</cite>, <cite>sequence</cite>, or <cite>TOAST table</cite>.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>object_name: str</dt>
<dd>The schema.obj for which to get the object type.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><cite>str</cite> of the object type.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.is_view">
<code class="descname">is_view</code><span class="sig-paren">(</span><em>object_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.is_view"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.is_view" title="Permalink to this definition">¶</a></dt>
<dd><p>Return true if the object is a view.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>object_name: str</dt>
<dd>The schema.obj to test if it’s a view.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><cite>bool</cite></dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.is_table">
<code class="descname">is_table</code><span class="sig-paren">(</span><em>object_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.is_table"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.is_table" title="Permalink to this definition">¶</a></dt>
<dd><p>Return true if the object is a table.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>object_name: str</dt>
<dd>The schema.obj to test if it’s a table.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><cite>bool</cite></dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_table_definition">
<code class="descname">get_table_definition</code><span class="sig-paren">(</span><em>table</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_table_definition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_table_definition" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the table definition (i.e. the create statement).</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>table: str</dt>
<dd>The schema.table for which to get the table definition.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd>str</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_table_definitions">
<code class="descname">get_table_definitions</code><span class="sig-paren">(</span><em>schema=None</em>, <em>table=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_table_definitions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_table_definitions" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the table definition (i.e. the create statement) for multiple tables.</p>
<p>This works similar to <cite>get_table_def</cite> except it runs a single query
to get the ddl for multiple tables. It supports SQL wildcards for
<cite>schema</cite> and <cite>table</cite>. Only returns the ddl for _tables_ that match
<cite>schema</cite> and <cite>table</cite> if they exist.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema to filter by.</dd>
<dt>table: str</dt>
<dd>The table to filter by.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><cite>list</cite> of dicts with matching tables.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_view_definition">
<code class="descname">get_view_definition</code><span class="sig-paren">(</span><em>view</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_view_definition"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_view_definition" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the view definition (i.e. the create statement).</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>view: str</dt>
<dd>The schema.view for which to get the view definition.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd>str</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.get_view_definitions">
<code class="descname">get_view_definitions</code><span class="sig-paren">(</span><em>schema=None</em>, <em>view=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.get_view_definitions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.get_view_definitions" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the view definition (i.e. the create statement) for multiple views.</p>
<p>This works similar to <cite>get_view_def</cite> except it runs a single query
to get the ddl for multiple views. It supports SQL wildcards for
<cite>schema</cite> and <cite>view</cite>. Only returns the ddl for _views_ that match
<cite>schema</cite> and <cite>view</cite> if they exist.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema to filter by.</dd>
<dt>view: str</dt>
<dd>The view to filter by.</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><cite>list</cite> of dicts with matching views.</dd>
</dl>
</dd></dl>

<dl class="staticmethod">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.split_full_table_name">
<em class="property">static </em><code class="descname">split_full_table_name</code><span class="sig-paren">(</span><em>full_table_name</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.split_full_table_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.split_full_table_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Split a full table name into its schema and table. If a schema isn’t
present, return <cite>public</cite> for the schema. Similarly, Redshift defaults
to the <cite>public</cite> schema, when one isn’t provided.</p>
<p>Eg:
<code class="docutils literal notranslate"><span class="pre">(schema,</span> <span class="pre">table)</span> <span class="pre">=</span> <span class="pre">Redshift.split_full_table_name(&quot;some_schema.some_table&quot;)</span></code></p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>full_table_name: str</dt>
<dd>The table name, as “schema.table”</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>tuple</dt>
<dd>A tuple containing (schema, table)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="staticmethod">
<dt id="parsons.databases.redshift.redshift.RedshiftTableUtilities.combine_schema_and_table_name">
<em class="property">static </em><code class="descname">combine_schema_and_table_name</code><span class="sig-paren">(</span><em>schema</em>, <em>table</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_table_utilities.html#RedshiftTableUtilities.combine_schema_and_table_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftTableUtilities.combine_schema_and_table_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a full table name by combining a schema and table.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema name</dd>
<dt>table: str</dt>
<dd>The table name</dd>
</dl>
</dd>
<dt><cite>Returns:</cite></dt>
<dd><dl class="first last docutils">
<dt>str</dt>
<dd>The combined full table name</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="schema-api">
<h3>Schema API<a class="headerlink" href="#schema-api" title="Permalink to this headline">¶</a></h3>
<p>Schema utilities are a series of helper methods, all built off of commonly
used SQL queries run against the Redshift database.</p>
<dl class="class">
<dt id="parsons.databases.redshift.redshift.RedshiftSchema">
<em class="property">class </em><code class="descclassname">parsons.databases.redshift.redshift.</code><code class="descname">RedshiftSchema</code><a class="reference internal" href="_modules/parsons/databases/redshift/rs_schema.html#RedshiftSchema"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftSchema" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftSchema.create_schema_with_permissions">
<code class="descname">create_schema_with_permissions</code><span class="sig-paren">(</span><em>schema</em>, <em>group=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_schema.html#RedshiftSchema.create_schema_with_permissions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftSchema.create_schema_with_permissions" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a Redshift schema (if it doesn’t already exist), and grants usage permissions to
a Redshift group (if specified).</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema name</dd>
<dt>group: str</dt>
<dd>The Redshift group name</dd>
<dt>type: str</dt>
<dd>The type of permissions to grant. Supports <cite>select</cite>, <cite>all</cite>, etc. (For
full list, see the
<a class="reference external" href="https://docs.aws.amazon.com/redshift/latest/dg/r_GRANT.html">Redshift GRANT docs</a>)</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="parsons.databases.redshift.redshift.RedshiftSchema.grant_schema_permissions">
<code class="descname">grant_schema_permissions</code><span class="sig-paren">(</span><em>schema</em>, <em>group</em>, <em>permissions_type='select'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/parsons/databases/redshift/rs_schema.html#RedshiftSchema.grant_schema_permissions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#parsons.databases.redshift.redshift.RedshiftSchema.grant_schema_permissions" title="Permalink to this definition">¶</a></dt>
<dd><p>Grants a Redshift group permissions to all tables within an existing schema.</p>
<dl class="docutils">
<dt><cite>Args:</cite></dt>
<dd><dl class="first last docutils">
<dt>schema: str</dt>
<dd>The schema name</dd>
<dt>group: str</dt>
<dd>The Redshift group name</dd>
<dt>type: str</dt>
<dd>The type of permissions to grant. Supports <cite>select</cite>, <cite>all</cite>, etc. (For
full list, see the
<a class="reference external" href="https://docs.aws.amazon.com/redshift/latest/dg/r_GRANT.html">Redshift GRANT docs</a>)</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="azure.html" class="btn btn-neutral float-right" title="Azure: Blob Storage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="airtable.html" class="btn btn-neutral" title="Airtable" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, The Movement Cooperative

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>